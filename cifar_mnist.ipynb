{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cuda visible devices\n",
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "\n",
    "import os\n",
    "if is_notebook():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" #\"1\"\n",
    "    # os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "    # os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "import matplotlib \n",
    "if not is_notebook():\n",
    "    matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import random as rnd\n",
    "from typing import Optional, Callable\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as  pd\n",
    "import torchvision.utils as vision_utils\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "from losses.divdis import DivDisLoss \n",
    "from losses.divdis import DivDisLoss\n",
    "from losses.ace import ACELoss\n",
    "from losses.dbat import DBatLoss\n",
    "from losses.loss_types import LossType\n",
    "\n",
    "from models.backbone import MultiHeadBackbone\n",
    "from models.multi_model import MultiNetModel\n",
    "from models.lenet import LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass \n",
    "@dataclass\n",
    "class Config():\n",
    "    seed: int = 45\n",
    "    loss_type: LossType = LossType.PROB\n",
    "    train_size: int = 500 \n",
    "    target_size: int = 5000\n",
    "    batch_size: int = 128\n",
    "    target_batch_size: int = 128\n",
    "    epochs: int = 100\n",
    "    heads: int = 2 \n",
    "    model: str = \"Resnet50\"\n",
    "    shared_backbone: bool = True\n",
    "    aux_weight: float = 1.0\n",
    "    mix_rate: Optional[float] = 0.5\n",
    "    l_01_mix_rate: Optional[float] = None # TODO: geneneralize\n",
    "    l_10_mix_rate: Optional[float] = None\n",
    "    gamma: Optional[float] = 1.0\n",
    "    mix_rate_lower_bound: Optional[float] = 0.5\n",
    "    inbalance_ratio: Optional[bool] = True\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-5\n",
    "    make_gifs: bool = True\n",
    "    device = \"mps\"\n",
    "    \n",
    "def post_init(conf: Config):\n",
    "    if conf.l_01_mix_rate is not None and conf.l_10_mix_rate is None:\n",
    "        conf.l_10_mix_rate = 0.0\n",
    "        if conf.mix_rate is None:\n",
    "            conf.mix_rate = conf.l_01_mix_rate\n",
    "        assert conf.mix_rate == conf.l_01_mix_rate\n",
    "    elif conf.l_01_mix_rate is None and conf.l_10_mix_rate is not None:\n",
    "        conf.l_01_mix_rate = 0.0\n",
    "        if conf.mix_rate is None:\n",
    "            conf.mix_rate = conf.l_10_mix_rate\n",
    "        assert conf.mix_rate == conf.l_10_mix_rate\n",
    "    elif conf.l_01_mix_rate is not None and conf.l_10_mix_rate is not None:\n",
    "        if conf.mix_rate is None:\n",
    "            conf.mix_rate = conf.l_01_mix_rate + conf.l_10_mix_rate\n",
    "        assert conf.mix_rate == conf.l_01_mix_rate + conf.l_10_mix_rate\n",
    "    else: # both are none \n",
    "        assert conf.mix_rate is not None\n",
    "        conf.l_01_mix_rate = conf.mix_rate / 2\n",
    "        conf.l_10_mix_rate = conf.mix_rate / 2\n",
    "    \n",
    "    if conf.mix_rate_lower_bound is None:\n",
    "        conf.mix_rate_lower_bound = conf.mix_rate\n",
    "\n",
    "    if conf.loss_type == LossType.DIVDIS:\n",
    "        conf.aux_weight = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize config \n",
    "conf = Config()\n",
    "#get config overrides if runnign from command line\n",
    "if not is_notebook():\n",
    "    import sys \n",
    "    conf_dict = OmegaConf.merge(OmegaConf.structured(conf), OmegaConf.from_cli(sys.argv[1:]))\n",
    "    conf = Config(**conf_dict)\n",
    "post_init(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(conf.seed)\n",
    "np.random.seed(conf.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: F.pad(x.repeat(3, 1, 1), (2, 2, 2, 2), 'constant', 0))\n",
    "])\n",
    "\n",
    "# get full datasets \n",
    "mnist_train = torchvision.datasets.MNIST('./data/mnist/', train=True, download=True, transform=mnist_transform)\n",
    "cifar_train = torchvision.datasets.CIFAR10('./data/cifar10/', train=True, download=True, transform=transform)\n",
    "mnist_test = torchvision.datasets.MNIST('./data/mnist/', train=False, download=True, transform=mnist_transform)\n",
    "cifar_test = torchvision.datasets.CIFAR10('./data/cifar10/', train=False, download=True, transform=transform)\n",
    "\n",
    "mnist_target, mnist_train, mnist_val = random_split(mnist_train, [10000, 45000, 5000], generator=torch.Generator().manual_seed(42))\n",
    "cifar_target, cifar_train, cifar_val = random_split(cifar_train, [10000, 35000, 5000], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that generates dataset of concatenated cifar and mnist images\n",
    "# 1-mix_rate is the number of cifar cars and 0's + cifar trucks and 1's (default)\n",
    "# 0_9 corresponds to cifar trucks and mnist 0's \n",
    "# 1_1 corresponds to cifar cars and mnist 1's \n",
    "def generate_dataset(mnist_data, cifar_data, mix_rate_0_9, mix_rate_1_1):\n",
    "    # filter by labels\n",
    "    mnist_0 = [(img, label) for img, label in mnist_data if label == 0]\n",
    "    mnist_1 = [(img, label) for img, label in mnist_data if label == 1]\n",
    "    cifar_1 = [(img, label) for img, label in cifar_data if label == 1]\n",
    "    cifar_9 = [(img, label) for img, label in cifar_data if label == 9]\n",
    "    # get number of samples\n",
    "    num_samples = min(len(mnist_0), len(mnist_1), len(cifar_1), len(cifar_9))\n",
    "    data_pairs = []\n",
    "    num_clean = int(num_samples * (1-mix_rate_0_9 - mix_rate_1_1)) \n",
    "    num_mixed_0_9 = int(num_samples * mix_rate_0_9) \n",
    "    num_mixed_1_1 = int(num_samples * mix_rate_1_1) \n",
    "    i = 0\n",
    "    for _ in range(num_clean // 2):\n",
    "        # cars and 0's\n",
    "        data_pairs.append(((cifar_1[i][0], mnist_0[i][0]), 0, (0, 0))) \n",
    "        # trucks and 1's\n",
    "        data_pairs.append(((cifar_9[i][0], mnist_1[i][0]), 1, (1, 1)))\n",
    "        i+=1\n",
    "    for _ in range(num_mixed_0_9):\n",
    "        # trucks and 0's\n",
    "        data_pairs.append(((cifar_9[i][0], mnist_0[i][0]), 1, (1, 0)))\n",
    "        i+=1\n",
    "    for _ in range(num_mixed_1_1):\n",
    "        # cars and 1's\n",
    "        data_pairs.append(((cifar_1[i][0], mnist_1[i][0]), 0, (0, 1)))\n",
    "        i+=1\n",
    "    # construct dataset\n",
    "    images, labels, group_labels = zip(*data_pairs)\n",
    "    # concatenate images\n",
    "    images = [torch.cat([cifar_img, mnist_img], dim=2) for cifar_img, mnist_img in images]\n",
    "    images = torch.stack(images)\n",
    "    # labels and group labels \n",
    "    labels = torch.tensor(labels).to(torch.float32)\n",
    "    group_labels = torch.tensor([list(gl) for gl in group_labels]).to(torch.float32)\n",
    "    # shuffle dataset\n",
    "    shuffle = torch.randperm(len(images))\n",
    "    images = images[shuffle]\n",
    "    labels = labels[shuffle]\n",
    "    group_labels = group_labels[shuffle]\n",
    "    dataset = TensorDataset(images, labels, group_labels)\n",
    "    return dataset\n",
    "\n",
    "# generate datasets\n",
    "source_train = generate_dataset(mnist_train, cifar_train, mix_rate_0_9=0.0, mix_rate_1_1=0.0)\n",
    "source_val = generate_dataset(mnist_val, cifar_val, mix_rate_0_9=0, mix_rate_1_1=0)\n",
    "target_train = generate_dataset(mnist_target, cifar_target, mix_rate_0_9=conf.l_01_mix_rate, mix_rate_1_1=conf.l_10_mix_rate)\n",
    "target_test = generate_dataset(mnist_test, cifar_test, mix_rate_0_9=0.25, mix_rate_1_1=0.25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum([gl[0] == gl[1] for _, _, gl in target_test]) / len(target_test) == 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot source images with vision_utils.make_grid\n",
    "cifar_mnist_grid = torch.stack([source_train[i][0] for i in range(20)])\n",
    "grid_img = vision_utils.make_grid(cifar_mnist_grid, nrow=10, normalize=True, padding=1)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot target train images with vision_utils.make_grid\n",
    "cifar_mnist_grid = torch.stack([target_train[i][0] for i in range(20)])\n",
    "grid_img = vision_utils.make_grid(cifar_mnist_grid, nrow=10, normalize=True, padding=1)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf.model == \"Resnet50\":\n",
    "    from torchvision import models\n",
    "    from torchvision.models.resnet import ResNet50_Weights\n",
    "    resnet50 = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "    model_builder = lambda: torch.nn.Sequential(*list(resnet50.children())[:-1])\n",
    "    feature_dim = 2048\n",
    "elif conf.model == \"LeNet\":\n",
    "    model_builder = lambda: partial(LeNet, num_classes=1, dropout_p=0.0)\n",
    "    feature_dim = 256\n",
    "if conf.shared_backbone:\n",
    "    net = MultiHeadBackbone(model_builder(), conf.heads, feature_dim)\n",
    "else:\n",
    "    net = MultiNetModel(heads=conf.heads, model_builder=model_builder)\n",
    "net = net.to(conf.device)\n",
    "opt = torch.optim.AdamW(net.parameters(), lr=conf.lr, weight_decay=conf.weight_decay)\n",
    "if conf.loss_type == LossType.DIVDIS:\n",
    "    loss_fn = DivDisLoss(heads=conf.heads)\n",
    "else:\n",
    "    loss_fn = ACELoss(\n",
    "        heads=conf.heads, \n",
    "        mode=conf.loss_type.value, \n",
    "        gamma=conf.gamma,\n",
    "        inbalance_ratio=conf.inbalance_ratio,\n",
    "        l_01_rate=conf.mix_rate_lower_bound / 2, \n",
    "        l_10_rate=conf.mix_rate_lower_bound / 2, \n",
    "        device=conf.device\n",
    "    )\n",
    "# data loaders \n",
    "source_train_loader = DataLoader(source_train, batch_size=conf.batch_size, shuffle=True)\n",
    "target_train_loader = DataLoader(target_train, batch_size=conf.target_batch_size, shuffle=True)\n",
    "source_val_loader = DataLoader(source_val, batch_size=conf.batch_size, shuffle=True)\n",
    "target_test_loader = DataLoader(target_test, batch_size=conf.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = defaultdict(list)\n",
    "# source_iter = iter(source_train_loader)\n",
    "target_iter = iter(target_train_loader)\n",
    "source_val_iter = iter(source_val_loader)\n",
    "target_test_iter = iter(target_test_loader)\n",
    "for epoch in range(conf.epochs):\n",
    "    for x, y, gl in tqdm(source_train_loader, desc=\"Source train\"):\n",
    "        x, y, gl = x.to(conf.device), y.to(conf.device), gl.to(conf.device)\n",
    "        logits = net(x)\n",
    "        logits_chunked = torch.chunk(logits, conf.heads, dim=-1)\n",
    "        losses = [F.binary_cross_entropy_with_logits(logit.squeeze(), y) for logit in logits_chunked]\n",
    "        xent = sum(losses)\n",
    "\n",
    "        try: \n",
    "            target_x, target_y, target_gl = next(target_iter)\n",
    "        except StopIteration:\n",
    "            target_iter = iter(target_train_loader)\n",
    "            target_x, target_y, target_gl = next(target_iter)\n",
    "        target_x, target_y, target_gl = target_x.to(conf.device), target_y.to(conf.device), target_gl.to(conf.device)\n",
    "        target_logits = net(target_x)\n",
    "\n",
    "        repulsion_loss_args = []\n",
    "        repulsion_loss = loss_fn(target_logits, *repulsion_loss_args)\n",
    "        full_loss = xent + conf.aux_weight * repulsion_loss\n",
    "        opt.zero_grad()\n",
    "        full_loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # try: \n",
    "        #     test_x, test_y, test_gl = next(target_test_iter)\n",
    "        # except StopIteration:\n",
    "        #     target_test_iter = iter(target_test_loader)\n",
    "        #     test_x, test_y, test_gl = next(target_test_iter)\n",
    "        # with torch.no_grad():\n",
    "        #     test_logits = net(test_x).squeeze()\n",
    "\n",
    "        # TODO: accuracy according to different group labels\n",
    "        # for i in range(conf.heads):\n",
    "        #     corrects_i = (test_logits[:, i] > 0) == test_y.flatten()\n",
    "        #     acc_i = corrects_i.float().mean()\n",
    "        #     metrics[f\"acc_{i}\"].append(acc_i.item())\n",
    "\n",
    "        #     corrects_i_alt = (test_logits[:, i] > 0) == test_gl[:, 1].flatten()\n",
    "        #     acc_i_alt = corrects_i_alt.float().mean()\n",
    "        #     metrics[f\"acc_{i}_alt\"].append(acc_i_alt.item())\n",
    "\n",
    "        metrics[f\"xent\"].append(xent.item())\n",
    "        metrics[f\"repulsion_loss\"].append(repulsion_loss.item())\n",
    "    # Compute aggregate metrics over the entire test set after each epoch\n",
    "    if (epoch + 1) % 1 == 0:  # You can adjust this to compute less frequently if needed\n",
    "        net.eval()\n",
    "        total_correct = torch.zeros(conf.heads)\n",
    "        total_correct_alt = torch.zeros(conf.heads)\n",
    "        total_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for test_x, test_y, test_gl in target_test_loader:\n",
    "                test_x, test_y, test_gl = test_x.to(conf.device), test_y.to(conf.device), test_gl.to(conf.device)\n",
    "                test_logits = net(test_x).squeeze()\n",
    "                total_samples += test_y.size(0)\n",
    "                \n",
    "                for i in range(conf.heads):\n",
    "                    total_correct[i] += ((test_logits[:, i] > 0) == test_y.flatten()).sum().item()\n",
    "                    total_correct_alt[i] += ((test_logits[:, i] > 0) == test_gl[:, 1].flatten()).sum().item()\n",
    "        \n",
    "        for i in range(conf.heads):\n",
    "            metrics[f\"epoch_acc_{i}\"].append((total_correct[i] / total_samples).item())\n",
    "            metrics[f\"epoch_acc_{i}_alt\"].append((total_correct_alt[i] / total_samples).item())\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1} Test Accuracies:\")\n",
    "        for i in range(conf.heads):\n",
    "            print(f\"Head {i}: {metrics[f'epoch_acc_{i}'][-1]:.4f}, Alt: {metrics[f'epoch_acc_{i}_alt'][-1]:.4f}\")\n",
    "        \n",
    "        net.train()\n",
    "\n",
    "# save metrics \n",
    "import json \n",
    "os.makedirs(\"metrics\", exist_ok=True)\n",
    "with open(f\"metrics/cifar_mnist.json\", \"w\") as f:\n",
    "    json.dump(metrics, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print loss\n",
    "plt.plot(metrics[\"xent\"], label=\"xent\", color=\"red\")\n",
    "plt.plot(metrics[\"repulsion_loss\"], label=\"repulsion_loss\", color=\"blue\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print metrics\n",
    "# plot acc_0 and acc_1 and acc_0_alt and acc_1_alt\n",
    "plt.plot(metrics[\"acc_0\"], label=\"acc_0\", color=\"blue\")\n",
    "plt.plot(metrics[\"acc_1\"], label=\"acc_1\", color=\"green\")\n",
    "plt.plot(metrics[\"acc_0_alt\"], label=\"acc_0_alt\", color=\"lightblue\")\n",
    "plt.plot(metrics[\"acc_1_alt\"], label=\"acc_1_alt\", color=\"lightgreen\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diverse-gen-KG5DY0Zz-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
