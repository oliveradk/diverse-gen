{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cuda visible devices\n",
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "\n",
    "import os\n",
    "if is_notebook():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\" #\"1\"\n",
    "    # os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "    # os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "import matplotlib \n",
    "if not is_notebook():\n",
    "    matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import random as rnd\n",
    "from typing import Optional, Callable\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass \n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as  pd\n",
    "import torchvision.utils as vision_utils\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from losses.divdis import DivDisLoss \n",
    "from losses.divdis import DivDisLoss\n",
    "from losses.ace import ACELoss\n",
    "from losses.conf import ConfLoss\n",
    "from losses.dbat import DBatLoss\n",
    "from losses.pass_through import PassThroughLoss\n",
    "from losses.smooth_top_loss import SmoothTopLoss\n",
    "from losses.loss_types import LossType\n",
    "\n",
    "from models.backbone import MultiHeadBackbone\n",
    "from models.multi_model import MultiNetModel, freeze_heads\n",
    "from models.lenet import LeNet\n",
    "\n",
    "from spurious_datasets.cifar_mnist import get_cifar_mnist_datasets\n",
    "from spurious_datasets.fmnist_mnist import get_fmnist_mnist_datasets\n",
    "from spurious_datasets.toy_grid import get_toy_grid_datasets\n",
    "from spurious_datasets.waterbirds import get_waterbirds_datasets\n",
    "from spurious_datasets.cub import get_cub_datasets\n",
    "from spurious_datasets.camelyon import get_camelyon_datasets\n",
    "from spurious_datasets.multi_nli import get_multi_nli_datasets\n",
    "from spurious_datasets.civil_comments import get_civil_comments_datasets\n",
    "from spurious_datasets.celebA import get_celebA_datasets\n",
    "\n",
    "from utils.utils import to_device, batch_size\n",
    "from utils.act_utils import get_acts_and_labels, plot_activations, transform_activations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config():\n",
    "    seed: int = 1\n",
    "    dataset: str = \"waterbirds\"\n",
    "    loss_type: LossType = LossType.DIVDIS\n",
    "    batch_size: int = 32\n",
    "    target_batch_size: int = 64\n",
    "    epochs: int = 10\n",
    "    heads: int = 2\n",
    "    binary: bool = False\n",
    "    model: str = \"Resnet50\"\n",
    "    shared_backbone: bool = True\n",
    "    source_weight: float = 1.0\n",
    "    aux_weight: float = 1.0\n",
    "    use_group_labels: bool = False\n",
    "    source_cc: bool = True\n",
    "    source_val_split: float = 0.2\n",
    "    target_val_split: float = 0.2\n",
    "    source_mix_rate: Optional[float] = 0.0\n",
    "    source_01_mix_rate: Optional[float] = None\n",
    "    source_10_mix_rate: Optional[float] = None\n",
    "    mix_rate: Optional[float] = None\n",
    "    target_01_mix_rate: Optional[float] = None\n",
    "    target_10_mix_rate: Optional[float] = None\n",
    "    aggregate_mix_rate: bool = False\n",
    "    mix_rate_lower_bound: Optional[float] = 0.5\n",
    "    target_01_mix_rate_lower_bound: Optional[float] = None\n",
    "    target_10_mix_rate_lower_bound: Optional[float] = None\n",
    "    pseudo_label_all_groups: bool = False\n",
    "    shuffle_target: bool = True\n",
    "    inbalance_ratio: Optional[bool] = False\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-4 # 1e-4\n",
    "    optimizer: str = \"sgd\"\n",
    "    lr_scheduler: Optional[str] = None \n",
    "    num_cycles: float = 0.5\n",
    "    frac_warmup: float = 0.05\n",
    "    max_length: int = 128\n",
    "    num_workers: int = 4\n",
    "    freeze_heads: bool = False\n",
    "    head_1_epochs: int = 5\n",
    "    dataset_length: Optional[int] = None\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    exp_dir: str = f\"output/{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "    plot_activations: bool = False\n",
    "\n",
    "def post_init(conf: Config, overrides: list[str]=[]):\n",
    "    if conf.target_01_mix_rate is not None and conf.target_10_mix_rate is None:\n",
    "        conf.target_10_mix_rate = 0.0\n",
    "        if conf.mix_rate is None:\n",
    "            conf.mix_rate = conf.target_01_mix_rate\n",
    "        assert conf.mix_rate == conf.target_01_mix_rate\n",
    "    elif conf.target_01_mix_rate is None and conf.target_10_mix_rate is not None:\n",
    "        conf.target_01_mix_rate = 0.0\n",
    "        if conf.mix_rate is None:\n",
    "            conf.mix_rate = conf.target_10_mix_rate\n",
    "        assert conf.mix_rate == conf.target_10_mix_rate\n",
    "    elif conf.target_01_mix_rate is not None and conf.target_10_mix_rate is not None:\n",
    "        if conf.mix_rate is None:\n",
    "            conf.mix_rate = conf.target_01_mix_rate + conf.target_10_mix_rate\n",
    "        assert conf.mix_rate == conf.target_01_mix_rate + conf.target_10_mix_rate\n",
    "    else: # both are none \n",
    "        if conf.mix_rate is not None:\n",
    "            conf.target_01_mix_rate = conf.mix_rate / 2\n",
    "            conf.target_10_mix_rate = conf.mix_rate / 2\n",
    "\n",
    "    if conf.freeze_heads and \"head_1_epochs\" not in overrides:\n",
    "        conf.head_1_epochs = round(conf.epochs / 2)\n",
    "    \n",
    "    if conf.source_mix_rate is not None:\n",
    "        conf.source_01_mix_rate = conf.source_mix_rate / 2\n",
    "        conf.source_10_mix_rate = conf.source_mix_rate / 2\n",
    "    \n",
    "\n",
    "    if conf.mix_rate_lower_bound is None:\n",
    "        conf.mix_rate_lower_bound = conf.mix_rate\n",
    "\n",
    "    if conf.target_01_mix_rate_lower_bound is None and conf.target_10_mix_rate_lower_bound is None and conf.mix_rate_lower_bound is not None:\n",
    "        conf.target_01_mix_rate_lower_bound = conf.mix_rate_lower_bound / 2\n",
    "        conf.target_10_mix_rate_lower_bound = conf.mix_rate_lower_bound / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if conf.loss_type == LossType.DBAT:\n",
    "#     conf.shared_backbone = False \n",
    "#     conf.freeze_heads = True\n",
    "#     conf.batch_size = 16\n",
    "#     conf.target_batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if conf.dataset in [\"waterbirds\", \"cub\"] and conf.loss_type == LossType.DIVDIS:\n",
    "#     conf.lr = 1e-3\n",
    "#     conf.weight_decay = 1e-4\n",
    "#     conf.epochs = 100\n",
    "#     conf.optimizer = \"sgd\"\n",
    "#     conf.batch_size = 16 \n",
    "#     conf.target_batch_size = 16\n",
    "#     conf.aux_weight = 10.0\n",
    "#     conf.shuffle_target = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if conf.dataset == \"waterbirds\" and conf.loss_type == LossType.TOPK:\n",
    "#     conf.optimizer = \"sgd\"\n",
    "#     conf.target_01_mix_rate_lower_bound = 0.38\n",
    "#     conf.target_10_mix_rate_lower_bound = 0.10\n",
    "#     conf.mix_rate_lower_bound = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # toy grid configs \n",
    "# if conf.dataset == \"toy_grid\":\n",
    "#     conf.model = \"toy_model\"\n",
    "#     conf.epochs = 128\n",
    "# if conf.model == \"ClipViT\":\n",
    "#     # conf.epochs = 5\n",
    "#     conf.lr = 1e-5\n",
    "# Resnet50 Configs\n",
    "# if conf.model == \"Resnet50\":\n",
    "#     conf.lr = 1e-4 # probably too high, should be 1e-4\n",
    "# if conf.dataset == \"multi_nli\" or conf.dataset == \"civil_comments\":\n",
    "#     conf.model = \"bert\"\n",
    "#     conf.lr = 1e-5\n",
    "#     conf.lr_scheduler = \"cosine\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get config overrides if runnign from command line\n",
    "overrride_keys = []\n",
    "if not is_notebook():\n",
    "    import sys \n",
    "    overrides = OmegaConf.from_cli(sys.argv[1:])\n",
    "    overrride_keys = overrides.keys()\n",
    "    conf_dict = OmegaConf.merge(OmegaConf.structured(conf), overrides)\n",
    "    conf = Config(**conf_dict)\n",
    "post_init(conf, overrride_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory from config\n",
    "from dataclasses import asdict\n",
    "exp_dir = conf.exp_dir\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "# save full config to exp_dir\n",
    "with open(f\"{exp_dir}/config.yaml\", \"w\") as f:\n",
    "    OmegaConf.save(config=conf, f=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(conf.seed)\n",
    "np.random.seed(conf.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transform = None\n",
    "pad_sides = False\n",
    "tokenizer = None\n",
    "if conf.model == \"Resnet50\":\n",
    "    from torchvision import models\n",
    "    from torchvision.models.resnet import ResNet50_Weights\n",
    "    resnet_builder = lambda: models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)    \n",
    "    model_builder = lambda: torch.nn.Sequential(*list(resnet_builder().children())[:-1])\n",
    "    resnet_50_transforms = ResNet50_Weights.IMAGENET1K_V1.transforms()\n",
    "    model_transform = transforms.Compose([\n",
    "        transforms.Resize(resnet_50_transforms.resize_size * 2, interpolation=resnet_50_transforms.interpolation),\n",
    "        transforms.CenterCrop(resnet_50_transforms.crop_size),\n",
    "        transforms.Normalize(mean=resnet_50_transforms.mean, std=resnet_50_transforms.std)\n",
    "    ])\n",
    "    pad_sides = True\n",
    "    feature_dim = 2048\n",
    "elif conf.model == \"ClipViT\":\n",
    "    # from models.clip_vit import ClipViT\n",
    "    # model_builder = lambda: ClipViT()\n",
    "    # feature_dim = 768\n",
    "    # input_size = 96\n",
    "    # model_transform = transforms.Compose([\n",
    "    #     transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BICUBIC)\n",
    "    # ])\n",
    "    import clip \n",
    "    preprocess = clip.clip._transform(224)\n",
    "    clip_builder = lambda: clip.load('ViT-B/32', device='cpu')[0]\n",
    "    model_builder = lambda: clip_builder().visual\n",
    "    model_transform = transforms.Compose([\n",
    "        preprocess.transforms[0],\n",
    "        preprocess.transforms[1],\n",
    "        preprocess.transforms[4]\n",
    "    ])\n",
    "    feature_dim = 512\n",
    "    pad_sides = True\n",
    "elif conf.model == \"bert\":\n",
    "    from transformers import BertModel, BertTokenizer\n",
    "    from models.hf_wrapper import HFWrapper\n",
    "    bert_builder = lambda: BertModel.from_pretrained('bert-base-uncased')\n",
    "    model_builder = lambda: HFWrapper(bert_builder())\n",
    "    feature_dim = 768\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "elif conf.model == \"toy_model\":\n",
    "    model_builder = lambda: nn.Sequential(\n",
    "        nn.Linear(2, 40), nn.ReLU(), nn.Linear(40, 40), nn.ReLU()\n",
    "    )\n",
    "    feature_dim = 40\n",
    "elif conf.model == \"LeNet\":\n",
    "    from models.lenet import LeNet\n",
    "    from functools import partial\n",
    "    model_builder = lambda: partial(LeNet, num_classes=1, dropout_p=0.0)\n",
    "    feature_dim = 256\n",
    "else: \n",
    "    raise ValueError(f\"Model {conf.model} not supported\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = None\n",
    "# TODO: there should be varaible n_classes for each feature \n",
    "classes = 2\n",
    "n_features = 2 \n",
    "is_img = True\n",
    "alt_index = 1\n",
    "\n",
    "if conf.dataset == \"toy_grid\":\n",
    "    source_train, source_val, target_train, target_val, target_test = get_toy_grid_datasets(\n",
    "        source_mix_rate_0_1=conf.source_01_mix_rate, \n",
    "        source_mix_rate_1_0=conf.source_10_mix_rate, \n",
    "        target_mix_rate_0_1=conf.target_01_mix_rate, \n",
    "        target_mix_rate_1_0=conf.target_10_mix_rate, \n",
    "    )\n",
    "elif conf.dataset == \"cifar_mnist\":\n",
    "    source_train, source_val, target_train, target_val, target_test = get_cifar_mnist_datasets(\n",
    "        source_mix_rate_0_1=conf.source_01_mix_rate, \n",
    "        source_mix_rate_1_0=conf.source_10_mix_rate, \n",
    "        target_mix_rate_0_1=conf.target_01_mix_rate, \n",
    "        target_mix_rate_1_0=conf.target_10_mix_rate, \n",
    "        transform=model_transform, \n",
    "        pad_sides=pad_sides\n",
    "    )\n",
    "\n",
    "elif conf.dataset == \"fmnist_mnist\":\n",
    "    source_train, source_val, target_train, target_val, target_test = get_fmnist_mnist_datasets(\n",
    "        source_mix_rate_0_1=conf.source_01_mix_rate, \n",
    "        source_mix_rate_1_0=conf.source_10_mix_rate, \n",
    "        target_mix_rate_0_1=conf.target_01_mix_rate, \n",
    "        target_mix_rate_1_0=conf.target_10_mix_rate, \n",
    "        transform=model_transform, \n",
    "        pad_sides=pad_sides\n",
    "    )\n",
    "elif conf.dataset == \"waterbirds\":\n",
    "    source_train, source_val, target_train, target_val, target_test = get_waterbirds_datasets(\n",
    "        mix_rate=conf.mix_rate, \n",
    "        source_cc=conf.source_cc,\n",
    "        transform=model_transform, \n",
    "        convert_to_tensor=True,\n",
    "        val_split=conf.source_val_split,\n",
    "        target_val_split=conf.target_val_split, \n",
    "        dataset_length=conf.dataset_length\n",
    "    )\n",
    "elif conf.dataset == \"cub\":\n",
    "    source_train, target_train, target_test = get_cub_datasets()\n",
    "    source_val = []\n",
    "    target_val = []\n",
    "elif conf.dataset.startswith(\"celebA\"):\n",
    "    if conf.dataset == \"celebA-0\":\n",
    "        gt_feat = \"Blond_Hair\"\n",
    "        spur_feat = \"Male\"\n",
    "        inv_spur_feat = True\n",
    "    elif conf.dataset == \"celebA-1\":\n",
    "        gt_feat = \"Mouth_Slightly_Open\"\n",
    "        spur_feat = \"Wearing_Lipstick\"\n",
    "        inv_spur_feat = False\n",
    "    elif conf.dataset == \"celebA-2\":\n",
    "        gt_feat = \"Wavy_Hair\"\n",
    "        spur_feat = \"High_Cheekbones\"\n",
    "        inv_spur_feat = False\n",
    "    else: \n",
    "        raise ValueError(f\"Dataset {conf.dataset} not supported\")\n",
    "    source_train, source_val, target_train, target_val, target_test = get_celebA_datasets(\n",
    "        mix_rate=conf.mix_rate, \n",
    "        source_cc=conf.source_cc,\n",
    "        transform=model_transform, \n",
    "        gt_feat=gt_feat,\n",
    "        spur_feat=spur_feat,\n",
    "        inv_spur_feat=inv_spur_feat,\n",
    "        dataset_length=conf.dataset_length\n",
    "    )\n",
    "elif conf.dataset == \"camelyon\":\n",
    "    source_train, source_val, target_train, target_val, target_test = get_camelyon_datasets(\n",
    "        transform=model_transform\n",
    "    )\n",
    "elif conf.dataset == \"civil_comments\":\n",
    "    source_train, source_val, target_train, target_val, target_test = get_civil_comments_datasets(\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=conf.max_length, \n",
    "        dataset_length=conf.dataset_length\n",
    "    )\n",
    "    is_img = False\n",
    "\n",
    "elif conf.dataset == \"multi_nli\":\n",
    "    source_train, source_val, target_train, target_val, target_test = get_multi_nli_datasets(\n",
    "        mix_rate=conf.mix_rate,\n",
    "        source_cc=conf.source_cc,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=conf.max_length, \n",
    "        dataset_length=conf.dataset_length\n",
    "    )\n",
    "    is_img = False\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Dataset {conf.dataset} not supported\")\n",
    "\n",
    "# if classes == 2 and conf.binary:\n",
    "#     classes = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot image \n",
    "img, y, gl = source_train[-1]\n",
    "# pad \n",
    "# to PIL image \n",
    "\n",
    "# img = transforms.ToPILImage()(img)\n",
    "# img\n",
    "if is_img and img.dim() == 3 and is_notebook():\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "    # show without axis \n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot target train images with vision_utils.make_grid\n",
    "if is_img and img.dim() == 3 and is_notebook():\n",
    "    img_tensor_grid = torch.stack([target_train[i][0] for i in range(20)])\n",
    "    grid_img = vision_utils.make_grid(img_tensor_grid, nrow=10, normalize=True, padding=1)\n",
    "    plt.imshow(grid_img.permute(1, 2, 0))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DivisibleBatchSampler(torch.utils.data.Sampler):\n",
    "    def __init__(self, dataset_size: int, batch_size: int, shuffle: bool = True):\n",
    "        self.dataset_size = dataset_size\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.rng = rnd.Random(42)\n",
    "        \n",
    "        # Calculate number of complete batches and total samples needed\n",
    "        self.num_batches = math.ceil(dataset_size / batch_size)\n",
    "        self.total_size = self.num_batches * batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Generate indices for the entire dataset\n",
    "        indices = list(range(self.dataset_size))\n",
    "        \n",
    "        if self.shuffle:\n",
    "            # Shuffle all indices\n",
    "            self.rng.shuffle(indices)\n",
    "            \n",
    "        # If we need more indices to make complete batches,\n",
    "        # randomly sample from existing indices\n",
    "        if self.total_size > self.dataset_size:\n",
    "            extra_indices = self.rnd.choices(indices, k=self.total_size - self.dataset_size)\n",
    "            indices.extend(extra_indices)\n",
    "            \n",
    "        assert len(indices) == self.total_size\n",
    "        return iter(indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_train_loader = DataLoader(\n",
    "    source_train, batch_size=conf.batch_size, num_workers=conf.num_workers, \n",
    "    sampler=DivisibleBatchSampler(len(source_train), conf.batch_size, shuffle=True), \n",
    ")\n",
    "if len(source_val) > 0:\n",
    "    source_val_loader = DataLoader(\n",
    "        source_val, batch_size=conf.batch_size, num_workers=conf.num_workers, \n",
    "        sampler=DivisibleBatchSampler(len(source_val), conf.batch_size, shuffle=False)\n",
    "    )\n",
    "# NOTE: shuffle \"should\" be true, but in divdis code its false, and this leads to substantial changes in worst goup result\n",
    "target_train_loader = DataLoader(\n",
    "    target_train, batch_size=conf.target_batch_size, num_workers=conf.num_workers, \n",
    "    sampler=DivisibleBatchSampler(len(target_train), conf.target_batch_size, shuffle=conf.shuffle_target)\n",
    ")\n",
    "if len(target_val) > 0:\n",
    "    target_val_loader = DataLoader(\n",
    "        target_val, batch_size=conf.target_batch_size, num_workers=conf.num_workers, \n",
    "        sampler=DivisibleBatchSampler(len(target_val), conf.target_batch_size, shuffle=False)\n",
    "    )\n",
    "target_test_loader = DataLoader(\n",
    "    target_test, batch_size=conf.batch_size, num_workers=conf.num_workers, shuffle=False\n",
    ")\n",
    "\n",
    "# classifiers\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "if conf.shared_backbone:\n",
    "    net = MultiHeadBackbone(model_builder(), conf.heads, feature_dim, classes if not conf.binary else 1)\n",
    "else:\n",
    "    print(\"warning, not using shared backbone untested\")\n",
    "    net = MultiNetModel(model_builder=model_builder, n_heads=conf.heads, feature_dim=feature_dim, classes=classes)\n",
    "net = net.to(conf.device)\n",
    "\n",
    "# optimizer\n",
    "if conf.optimizer == \"adamw\":\n",
    "    opt = torch.optim.AdamW(net.parameters(), lr=conf.lr, weight_decay=conf.weight_decay)\n",
    "elif conf.optimizer == \"sgd\":\n",
    "    opt = torch.optim.SGD(net.parameters(), lr=conf.lr, weight_decay=conf.weight_decay, momentum=0.9)\n",
    "else: \n",
    "    raise ValueError(f\"Optimizer {conf.optimizer} not supported\")\n",
    "num_steps = conf.epochs * len(source_train_loader)\n",
    "if conf.lr_scheduler == \"cosine\":       \n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        opt, \n",
    "        num_warmup_steps=num_steps * conf.frac_warmup, \n",
    "        num_training_steps=num_steps, \n",
    "        num_cycles=conf.num_cycles\n",
    "    )\n",
    "else: \n",
    "    # constant learning rate\n",
    "    scheduler = None\n",
    "\n",
    "# loss function\n",
    "if conf.loss_type == LossType.DIVDIS:\n",
    "    loss_fn = DivDisLoss(heads=conf.heads)\n",
    "elif conf.loss_type == LossType.DBAT:\n",
    "    loss_fn = DBatLoss(heads=conf.heads)\n",
    "elif conf.loss_type == LossType.CONF:\n",
    "    loss_fn = ConfLoss()\n",
    "elif conf.loss_type == LossType.SMOOTH:\n",
    "    loss_fn = SmoothTopLoss(\n",
    "        criterion=partial(F.binary_cross_entropy_with_logits, reduction='none'), \n",
    "        device=conf.device\n",
    "    )\n",
    "elif conf.loss_type == LossType.ERM:\n",
    "    loss_fn = PassThroughLoss()\n",
    "elif conf.loss_type in [LossType.TOPK, LossType.EXP, LossType.PROB]:\n",
    "    if conf.aggregate_mix_rate:\n",
    "        mix_rate = conf.mix_rate_lower_bound \n",
    "        group_mix_rates = None\n",
    "    else:\n",
    "        mix_rate = None \n",
    "        group_mix_rates = {(0, 1): conf.target_01_mix_rate_lower_bound, (1, 0): conf.target_10_mix_rate_lower_bound}\n",
    "    loss_fn = ACELoss(\n",
    "        heads=conf.heads, \n",
    "        classes=classes,\n",
    "        binary=conf.binary,\n",
    "        mode=conf.loss_type.value, \n",
    "        inbalance_ratio=conf.inbalance_ratio,\n",
    "        mix_rate=mix_rate,\n",
    "        group_mix_rates=group_mix_rates,\n",
    "        pseudo_label_all_groups=conf.pseudo_label_all_groups,\n",
    "        device=conf.device\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Loss type {conf.loss_type} not supported\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# visualize data using first two principle componets of final layer activations\n",
    "if is_notebook() and conf.plot_activations:\n",
    "    model = model_builder()\n",
    "    model = model.to(conf.device)\n",
    "    activations, labels = get_acts_and_labels(model, target_test_loader)\n",
    "    activations_pca, pca = transform_activations(activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_notebook() and conf.plot_activations:\n",
    "    group_labels = labels[:, 0] * 2 + labels[:, 1]\n",
    "    plt.scatter(activations_pca[:, 0], activations_pca[:, 1], c=group_labels.to('cpu'), cmap=\"viridis\")\n",
    "    plt.title(\"Group labels\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "if is_notebook() and conf.plot_activations:\n",
    "    component_range = [2**i for i in range(1, 9)]\n",
    "    component_range = [i for i in component_range if i <= feature_dim]\n",
    "    n_components_accs = []\n",
    "    for n_components in tqdm(component_range):\n",
    "        pca = PCA(n_components=n_components)\n",
    "        pca.fit(activations)\n",
    "        activations_pca = pca.transform(activations)\n",
    "        # fit probe \n",
    "        lr = LogisticRegression(max_iter=1000)\n",
    "        lr.fit(activations_pca, labels[:, 0].to('cpu').numpy())\n",
    "        acc = lr.score(activations_pca, labels[:, 0].to('cpu').numpy())\n",
    "        n_components_accs.append(acc)\n",
    "    plt.plot(component_range, n_components_accs, label=\"accuracy\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit linear probe \n",
    "if is_notebook() and conf.plot_activations:\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    lr = LogisticRegression(max_iter=10000)\n",
    "    lr.fit(activations.to('cpu').numpy(), labels[:, 0].to('cpu').numpy())\n",
    "    # get accuracy \n",
    "    acc = lr.score(activations.to('cpu').numpy(), labels[:, 0].to('cpu').numpy())\n",
    "    print(f\"Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_notebook() and conf.plot_activations:\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    # Second 3D plot for group labels\n",
    "    ax3 = fig.add_subplot(121, projection='3d')\n",
    "    scatter3 = ax3.scatter(activations_pca[:, 0], activations_pca[:, 1], activations_pca[:,2], \n",
    "                        c=group_labels.to('cpu'), cmap=\"viridis\")\n",
    "    ax3.view_init(25, 210, 0)\n",
    "    ax3.set_title('Group labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_notebook() and conf.plot_activations:\n",
    "    fig = plot_activations(model=net.backbone, loader=target_test_loader, device=conf.device)\n",
    "    fig.savefig(f\"{exp_dir}/activations_pretrain.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_src_losses(logits, y, gl):\n",
    "    logits_chunked = torch.chunk(logits, conf.heads, dim=-1)\n",
    "    labels = torch.cat([y, y], dim=-1) if not conf.use_group_labels else gl\n",
    "    labels_chunked = torch.chunk(labels, conf.heads, dim=-1)\n",
    "\n",
    "    if conf.binary:\n",
    "        losses = [F.binary_cross_entropy_with_logits(logit.squeeze(), y.squeeze().to(torch.float32)) for logit, y in zip(logits_chunked, labels_chunked)]\n",
    "    else:\n",
    "        assert logits_chunked[0].shape == (logits.size(0), classes), logits_chunked[0].shape\n",
    "        losses = [F.cross_entropy(logit.squeeze(), y.squeeze().to(torch.long)) \n",
    "                  for logit, y in zip(logits_chunked, labels_chunked)]\n",
    "    return losses\n",
    "\n",
    "def compute_corrects(logits: torch.Tensor, head: int, y: torch.Tensor, binary: bool):\n",
    "    if binary:\n",
    "        return ((logits[:, head] > 0) == y.flatten()).sum().item()\n",
    "    else:\n",
    "        logits = logits.view(logits.size(0), conf.heads, classes)\n",
    "        return (logits[:, head].argmax(dim=-1) == y).sum().item()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "class Logger():\n",
    "    def __init__(self, exp_dir):\n",
    "        self.exp_dir = exp_dir\n",
    "        self.metrics = defaultdict(list)\n",
    "        self.tb_writer = SummaryWriter(log_dir=exp_dir)\n",
    "    \n",
    "    def add_scalar(self, parition, name, value, step=None, to_metrics=True, to_tb=True):\n",
    "        if to_metrics:\n",
    "            self.metrics[f\"{parition}_{name}\"].append(value)\n",
    "        if to_tb:\n",
    "            self.tb_writer.add_scalar(f\"{parition}/{name}\", value, step)\n",
    "\n",
    "    def flush(self):\n",
    "        self.tb_writer.flush()\n",
    "        # save metrics to json\n",
    "        with open(f\"{self.exp_dir}/metrics.json\", \"w\") as f:\n",
    "            json.dump(self.metrics, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def eval(model, loader, device, loss_fn, use_labels=False, stage: str = \"Evaluating\"): \n",
    "    group_label_ls = list(product(range(classes), repeat=n_features))\n",
    "\n",
    "    # loss \n",
    "    losses = []\n",
    "\n",
    "    # accuracy \n",
    "    total_corrects_by_groups = {\n",
    "        group_label: torch.zeros(conf.heads)\n",
    "        for group_label in group_label_ls\n",
    "    }\n",
    "    total_corrects_alt_by_groups = {\n",
    "        group_label: torch.zeros(conf.heads)\n",
    "        for group_label in group_label_ls\n",
    "    }\n",
    "    total_samples = 0\n",
    "    total_samples_by_groups = {\n",
    "        group_label: 0\n",
    "        for group_label in group_label_ls\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y, gl in tqdm(loader, desc=stage):\n",
    "            x, y, gl = to_device(x, y, gl, conf.device)\n",
    "            logits = model(x)\n",
    "            # print(test_logits.shape)\n",
    "            total_samples += logits.size(0)\n",
    "            if use_labels and loss_fn is not None:\n",
    "                loss = loss_fn(logits, y, gl)\n",
    "            elif loss_fn is not None:\n",
    "                loss = loss_fn(logits)\n",
    "            else: \n",
    "                loss = torch.tensor(0.0, device=conf.device)\n",
    "            if torch.isnan(loss):\n",
    "                print(f\"Warning: Nan Loss (likely due to batch size and target loss) \"\n",
    "                f\"Batch size: {logits.size(0)}, Loss: {conf.loss_type}\")\n",
    "            else:\n",
    "                losses.append(loss)\n",
    "\n",
    "            # parition instances into groups based on group labels \n",
    "            logits_by_group = {}\n",
    "            for group_label in group_label_ls:\n",
    "                group_label_mask = torch.all(gl == torch.tensor(group_label).to(device), dim=1)\n",
    "                # print(\"group label mask\", group_label_mask.shape)\n",
    "                logits_by_group[group_label] = logits[group_label_mask]\n",
    "            # print(\"group logit shapes\", [v.shape for v in logits_by_group.values()])\n",
    "            \n",
    "            for group_label, group_logits in logits_by_group.items():\n",
    "                num_examples_group = group_logits.size(0)\n",
    "                total_samples_by_groups[group_label] += num_examples_group\n",
    "                group_labels = torch.tensor(group_label).repeat(num_examples_group, 1).to(device)\n",
    "                # print(\"group label shapes\", group_labels[:, 0].shape)\n",
    "                for i in range(conf.heads):\n",
    "                    total_corrects_by_groups[group_label][i] += compute_corrects(group_logits, i, group_labels[:, 0], conf.binary)\n",
    "                    total_corrects_alt_by_groups[group_label][i] += compute_corrects(group_logits, i, group_labels[:, 1], conf.binary)\n",
    "    \n",
    "    total_corrects = torch.stack([gl_corrects for gl_corrects in total_corrects_by_groups.values()], dim=0).sum(dim=0)\n",
    "    total_corrects_alt = torch.stack([gl_corrects for gl_corrects in total_corrects_alt_by_groups.values()], dim=0).sum(dim=0)\n",
    "\n",
    "    # average metrics\n",
    "    metrics = {}\n",
    "    for i in range(conf.heads):\n",
    "        metrics[f\"acc_{i}\"] = (total_corrects[i] / total_samples).item()\n",
    "        metrics[f\"acc_alt_{i}\"] = (total_corrects_alt[i] / total_samples).item()\n",
    "    \n",
    "    if loss_fn is not None:\n",
    "        metrics[\"loss\"] = torch.mean(torch.tensor(losses)).item()\n",
    "    # group acc per head\n",
    "    for group_label in group_label_ls:\n",
    "        for i in range(conf.heads): \n",
    "            metrics[f\"acc_{i}_{group_label}\"] = (total_corrects_by_groups[group_label][i] / total_samples_by_groups[group_label]).item()\n",
    "            metrics[f\"acc_alt_{i}_{group_label}\"] = (total_corrects_alt_by_groups[group_label][i] / total_samples_by_groups[group_label]).item()\n",
    "    # worst group acc per head\n",
    "    for i in range(conf.heads):\n",
    "        metrics[f\"worst_acc_{i}\"] = min([metrics[f\"acc_{i}_{group_label}\"] for group_label in group_label_ls])\n",
    "\n",
    "    # add group counts \n",
    "    for group_label in group_label_ls:\n",
    "        metrics[f\"count_{group_label}\"] = total_samples_by_groups[group_label]\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change diciotary values to source loss, target loss\n",
    "from itertools import cycle\n",
    "logger = Logger(exp_dir)\n",
    "try:\n",
    "    if conf.freeze_heads:\n",
    "        # freeze second head (for dbat)\n",
    "        net.freeze_head(1)\n",
    "    for epoch in range(conf.epochs):\n",
    "        train_loader = zip(source_train_loader, cycle(target_train_loader))\n",
    "        loader_len = len(source_train_loader)\n",
    "        # train\n",
    "        for batch_idx, (source_batch, target_batch) in tqdm(enumerate(train_loader), desc=\"Source train\", total=loader_len):\n",
    "            # freeze heads for dbat\n",
    "            if conf.freeze_heads and epoch == conf.head_1_epochs: \n",
    "                net.unfreeze_head(1)\n",
    "                net.freeze_head(0)\n",
    "            \n",
    "            # source\n",
    "            x, y, gl = to_device(*source_batch, conf.device)\n",
    "            logits = net(x)\n",
    "            losses = compute_src_losses(logits, y, gl)\n",
    "            xent = torch.mean(torch.stack(losses))\n",
    "            logger.add_scalar(\"train\", \"source_loss\", xent.item(), epoch * loader_len + batch_idx)\n",
    "            \n",
    "            # target\n",
    "            target_x, target_y, target_gl = to_device(*target_batch, conf.device)\n",
    "            target_logits = net(target_x)\n",
    "            target_loss = loss_fn(target_logits)\n",
    "            logger.add_scalar(\"train\", \"target_loss\", target_loss.item(), epoch * loader_len + batch_idx)\n",
    "            logger.add_scalar(\"train\", \"weighted_target_loss\", conf.aux_weight * target_loss.item(), epoch * loader_len + batch_idx, to_metrics=False, to_tb=True)\n",
    "            # don't compute target loss before second head begins training\n",
    "            if conf.freeze_heads and epoch < conf.head_1_epochs: \n",
    "                target_loss = torch.tensor(0.0, device=conf.device)\n",
    "            \n",
    "            # full loss \n",
    "            full_loss = conf.source_weight * xent + conf.aux_weight * target_loss\n",
    "            logger.add_scalar(\"train\", \"loss\", full_loss.item(), epoch * loader_len + batch_idx)\n",
    "            \n",
    "            # backprop\n",
    "            opt.zero_grad()\n",
    "            full_loss.backward()\n",
    "            opt.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "        \n",
    "        # eval\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            net.eval()\n",
    "            ### Validation \n",
    "            # source\n",
    "            total_val_loss = 0.0\n",
    "            total_val_weighted_loss = 0.0\n",
    "            if len(source_val) > 0:\n",
    "                src_loss_fn = lambda x, y, gl: sum(compute_src_losses(x, y, gl))\n",
    "                source_val_metrics = eval(net, source_val_loader, conf.device, src_loss_fn, use_labels=True, stage=\"Source Val\")\n",
    "                for k, v in source_val_metrics.items():\n",
    "                    if 'count' not in k:\n",
    "                        logger.add_scalar(\"val\", f\"source_{k}\", v, epoch)\n",
    "                total_val_loss += source_val_metrics[\"loss\"]\n",
    "                total_val_weighted_loss += total_val_loss\n",
    "            # target\n",
    "            weighted_target_val_loss = 0.0\n",
    "            if len(target_val) > 0:  \n",
    "                target_val_metrics = eval(net, target_val_loader, conf.device, loss_fn, use_labels=False, stage=\"Target Val\")\n",
    "                for k, v in target_val_metrics.items():\n",
    "                    if 'count' not in k:\n",
    "                        logger.add_scalar(\"val\", f\"target_{k}\", v, epoch)\n",
    "                weighted_target_val_loss = target_val_metrics[\"loss\"] * conf.aux_weight\n",
    "                logger.add_scalar(\"val\", \"target_weighted_loss\", weighted_target_val_loss, epoch)\n",
    "                total_val_loss += target_val_metrics[\"loss\"]    \n",
    "                total_val_weighted_loss += weighted_target_val_loss\n",
    "            # total\n",
    "            logger.add_scalar(\"val\", \"loss\", total_val_loss, epoch)\n",
    "            logger.add_scalar(\"val\", \"weighted_loss\", total_val_weighted_loss, epoch)\n",
    "\n",
    "            ### Test\n",
    "            target_test_metrics = eval(net, target_test_loader, conf.device, None, use_labels=False, stage=\"Target Test\")\n",
    "            for k, v in target_test_metrics.items():\n",
    "                if 'count' not in k:\n",
    "                    logger.add_scalar(\"test\", k, v, epoch)\n",
    "\n",
    "\n",
    "            ### Print Results\n",
    "            print(f\"Epoch {epoch + 1} Eval Results:\")\n",
    "            # print validation losses\n",
    "            if len(source_val) > 0:\n",
    "                print(f\"Source validation loss: {logger.metrics['val_source_loss'][-1]:.4f}\")\n",
    "            if len(target_val) > 0:\n",
    "                print(f\"Target validation loss {logger.metrics['val_target_loss'][-1]:.4f}\")\n",
    "            print(f\"Validation loss: {logger.metrics['val_loss'][-1]:.4f}\")\n",
    "            if len(target_val) > 0:\n",
    "                for group_label in product(range(2), repeat=gl.shape[1]):\n",
    "                    print(f\"Group {group_label} validation count: {target_val_metrics[f'count_{group_label}']}\")\n",
    "            # print test accuracies (total and group)\n",
    "            print(\"\\n=== Test Accuracies ===\")\n",
    "            # Overall accuracy for each head\n",
    "            print(\"\\nOverall Accuracies:\")\n",
    "            for i in range(conf.heads):\n",
    "                print(f\"Head {i}:  Main: {logger.metrics[f'test_acc_{i}'][-1]:.4f}  |  Alt: {logger.metrics[f'test_acc_alt_{i}'][-1]:.4f}\")\n",
    "            # Group-wise accuracies\n",
    "            print(\"\\nGroup-wise Accuracies:\")\n",
    "            for group_label in product(range(2), repeat=gl.shape[1]):\n",
    "                print(f\"\\nGroup {group_label}, count: {target_test_metrics[f'count_{group_label}']}:\")\n",
    "                for i in range(conf.heads):\n",
    "                    print(f\"Head {i}:  Main: {logger.metrics[f'test_acc_{i}_{group_label}'][-1]:.4f}  |  Alt: {logger.metrics[f'test_acc_alt_{i}_{group_label}'][-1]:.4f}\")\n",
    "\n",
    "            # plot activations \n",
    "            if conf.plot_activations:   \n",
    "                fig = plot_activations(\n",
    "                    model=net.backbone, loader=target_test_loader, device=conf.device\n",
    "                )\n",
    "                fig.savefig(f\"{exp_dir}/activations_{epoch}.png\")\n",
    "                plt.close()\n",
    "            \n",
    "            net.train()\n",
    "finally:\n",
    "    logger.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diverse-gen-KG5DY0Zz-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
