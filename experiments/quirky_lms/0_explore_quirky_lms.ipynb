{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on Paper\n",
    "\n",
    "https://arxiv.org/pdf/2312.01037\n",
    "\n",
    "ok so they don't \"natively\" use the target distribution during training, so the setup is kind of disanalogous, but still could be interesting\n",
    "\n",
    "ok so looks like cupbearer already has an implementation of one of the models and tasks \n",
    "\n",
    "we probably want more expansive stuff though, and not to tie down to cupbearer / only training probes \n",
    "\n",
    "-eh maybe its fine in this case b/c we're sort of assumign a fixed predictor? \n",
    "\n",
    "no I mean you could assume an initially misaligned classifier, and then you learn multiple generalizations on top \n",
    "\n",
    "so I guess we'd want to compare to the baseline of just \"finetune more on trusted data\" - seems reasonable \n",
    "\n",
    "\n",
    "ok given that, cupbearer probably doesn't make sense b/c we want the infrastructure to finetune the whole model\n",
    "\n",
    "so instead, lets take a look at eleuther's code\n",
    "\n",
    "wait are trained models actually binary classifiers? - no they're generative models but trained to output one of two tokens\n",
    "\n",
    "\n",
    "ok so a few thing to try: \n",
    "- use ``probe'' topk, just using the activations \n",
    "- use ``full model'' topk, duplicating the model and training end to end \n",
    "\n",
    "yeah that seems fine for now. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HUGGINGFACE_TOKEN\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/ucb/oliveradk/miniforge3/envs/od_3_10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name = \"sciq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so first run extract hiddens\n",
    "\n",
    "# next..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 915/915 [00:00<00:00, 3.31MB/s]\n",
      "Downloading data: 100%|██████████| 1.27M/1.27M [00:00<00:00, 3.01MB/s]\n",
      "Downloading data: 100%|██████████| 263k/263k [00:00<00:00, 505kB/s]\n",
      "Downloading data: 100%|██████████| 251k/251k [00:00<00:00, 878kB/s]\n",
      "Generating train split: 100%|██████████| 9629/9629 [00:00<00:00, 169362.89 examples/s]\n",
      "Generating validation split: 100%|██████████| 2000/2000 [00:00<00:00, 220399.04 examples/s]\n",
      "Generating test split: 100%|██████████| 2000/2000 [00:00<00:00, 240623.26 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# load data \n",
    "data = load_dataset(f\"EleutherAI/quirky_{dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# create untrusted / trusted train data\n",
    "# load pretrained model for data \n",
    "# run code for training probes, but with topk loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "od_3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
