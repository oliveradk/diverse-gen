{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cuda visible devices\n",
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "\n",
    "import os\n",
    "if is_notebook():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" #\"1\"\n",
    "    # os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "    # os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "import matplotlib \n",
    "if not is_notebook():\n",
    "    matplotlib.use('Agg')\n",
    "\n",
    "# set directory\n",
    "os.chdir(\"/nas/ucb/oliveradk/diverse-gen/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now incomplete spurious correlation: \n",
    "#   waterbirds\n",
    "\n",
    "# other notebooks:\n",
    "# multi-class classification: \n",
    "#   multi-nli-cc\n",
    "\n",
    "# known group labels\n",
    "# waterbirds (normal)\n",
    "# mulit-nli cc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from losses.loss_types import LossType\n",
    "from utils.exp_utils import get_executor, run_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_NAME = \"measurement_tampering.py\"\n",
    "EXP_DIR = \"output/mtd_hparam_sweep\"\n",
    "n_trials = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diamonds hparams: \n",
    "## full model: 2e-5 \n",
    "## probe: 2e-4 \n",
    "## ground truth probes: 2e-4 \n",
    "## num epochs: 5 \n",
    "## num warmup stesp: 64 \n",
    "\n",
    "# generated stories hparams: \n",
    "## full model: 1e-6\n",
    "## probes: 5e-4 \n",
    "## ground truth probes: 5e-3 \n",
    "## num epochs: 4 \n",
    "## num warmup stesp: 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 2\n",
    "\n",
    "method_configs = {\n",
    "    \"TopK 0.1\": {\"loss_type\": LossType.TOPK},\n",
    "    \"DivDis\": {\"loss_type\": LossType.DIVDIS},\n",
    "}\n",
    "\n",
    "# TODO: set frac warmup steps appropriately for each dataset\n",
    "dimaond_env_configs = {\n",
    "    f\"diamonds-seed{i}\": {\n",
    "        \"dataset\": f\"diamonds-seed{i}\", \n",
    "        \"model\": f\"codegen-350M-mono-measurement_pred-diamonds-seed{i}\", \n",
    "        \"bootstrap_eval\": False, \n",
    "        \"frac_warmup_steps\": 0.10, # 64 step\n",
    "    } \n",
    "    for i in range(8)\n",
    "}\n",
    "dataset_configs = {\n",
    "   **dimaond_env_configs,\n",
    "   \"generated-stories\": {\n",
    "        \"dataset\": \"generated_stories\", \n",
    "        \"model\": \"pythia-1_4b-deduped-measurement_pred-generated_stories\", \n",
    "        \"bootstrap_eval\": True, \n",
    "        \"micro_batch_size\": 2, \n",
    "        \"max_length\": 1536, \n",
    "        \"feature_dim\": 2048, \n",
    "        \"frac_warmup_steps\": 0.15, # 8 steps\n",
    "   }\n",
    "}\n",
    "\n",
    "dataset_method_hparam_ranges = {\n",
    "    **{f\"diamonds-seed{i}\": {\n",
    "        \"TopK 0.1\": {\"lr\": [2e-5, 1e-3], \"aux_weight\": [1e-0, 3e-1]},\n",
    "        \"DivDis\": {\"lr\": [2e-5, 1e-3], \"aux_weight\": [1e-0, 1e-2]},\n",
    "        } for i in range(8)\n",
    "    },\n",
    "    \"generated-stories\": {\n",
    "        \"TopK 0.1\": {\"lr\": [1e-6, 1e-3], \"aux_weight\": [1e-0, 1e-2]},\n",
    "        \"DivDis\": {\"lr\": [1e-6, 1e-3], \"aux_weight\": [1e-0, 1e-2]},\n",
    "    }\n",
    "}\n",
    "\n",
    "def sample_hparams(dataset_name, method_name):\n",
    "    method_ranges = dataset_method_hparam_ranges[dataset_name][method_name]\n",
    "    samples_hparams = {}\n",
    "    for param_name, param_range in method_ranges.items():\n",
    "        samples_hparams[param_name] = 10**(np.random.uniform(param_range[0], param_range[1]))\n",
    "    return samples_hparams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {(ds_name, method_name): {**ds_config, **method_config}\n",
    "           for (ds_name, ds_config), (method_name, method_config) in product(dataset_configs.items(), method_configs.items())}\n",
    "\n",
    "sampled_configs = []\n",
    "for (ds_name, method_name), conf in configs.items():\n",
    "    n_trials_ds = n_trials if not ds_name.startswith(\"diamonds\") else n_trials // 8\n",
    "    for i in range(n_trials_ds):\n",
    "        samples_hparams = sample_hparams(ds_name, method_name)\n",
    "        conf.update(samples_hparams)\n",
    "        seed = np.random.randint(0, 1000000)\n",
    "        conf[\"seed\"] = seed\n",
    "        conf[\"num_epochs\"] = N_EPOCHS\n",
    "        sampled_configs.append(conf)\n",
    "\n",
    "def get_conf_exp_dir(ds_name, method_name, aux_weight, lr):\n",
    "    return Path(EXP_DIR, f\"{ds_name}_{method_name}/{aux_weight}-{lr}\")\n",
    "\n",
    "for (ds_name, method_name), conf in configs.items():\n",
    "    exp_dir = get_conf_exp_dir(ds_name, method_name, conf[\"aux_weight\"], conf[\"lr\"])\n",
    "    conf[\"exp_dir\"] = exp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_80gb_nodes = [\"ddpg\", \"dqn\", \"gail\", \"gan\",\"ppo\", \"vae\"]\n",
    "slurm_exclude = [f\"{node}.ist.berkeley.edu\" for node in non_80gb_nodes]\n",
    "\n",
    "executor = get_executor(exp_dir, mem_gb=32, slurm_exclude=slurm_exclude)\n",
    "jobs = run_experiments(sampled_configs, executor, SCRIPT_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "od_3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
