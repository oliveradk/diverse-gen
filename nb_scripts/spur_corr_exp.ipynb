{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cuda visible devices\n",
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "\n",
    "import os\n",
    "if is_notebook():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" #\"1\"\n",
    "    # os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "    # os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "import matplotlib \n",
    "if not is_notebook():\n",
    "    matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import random as rnd\n",
    "from typing import Optional, Callable\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass \n",
    "from itertools import product\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as  pd\n",
    "import torchvision.utils as vision_utils\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from losses.divdis import DivDisLoss \n",
    "from losses.divdis import DivDisLoss\n",
    "from losses.ace import ACELoss\n",
    "from losses.conf import ConfLoss\n",
    "from losses.dbat import DBatLoss\n",
    "from losses.pass_through import PassThroughLoss\n",
    "from losses.smooth_top_loss import SmoothTopLoss\n",
    "from losses.loss_types import LossType\n",
    "\n",
    "from models.backbone import MultiHeadBackbone\n",
    "from models.multi_model import MultiNetModel, freeze_heads\n",
    "from models.lenet import LeNet\n",
    "\n",
    "from spurious_datasets.cifar_mnist import get_cifar_mnist_datasets\n",
    "from spurious_datasets.fmnist_mnist import get_fmnist_mnist_datasets\n",
    "from spurious_datasets.toy_grid import get_toy_grid_datasets\n",
    "from spurious_datasets.waterbirds import get_waterbirds_datasets\n",
    "from spurious_datasets.cub import get_cub_datasets\n",
    "from spurious_datasets.camelyon import get_camelyon_datasets\n",
    "from spurious_datasets.multi_nli import get_multi_nli_datasets\n",
    "from spurious_datasets.civil_comments import get_civil_comments_datasets\n",
    "from spurious_datasets.celebA import get_celebA_datasets\n",
    "\n",
    "from utils.utils import to_device, batch_size, feature_label_ls\n",
    "from utils.logger import Logger\n",
    "from utils.act_utils import get_acts_and_labels, plot_activations, compute_probe_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import field\n",
    "\n",
    "@dataclass\n",
    "class Config():\n",
    "    seed: int = 1\n",
    "    dataset: str = \"waterbirds\"\n",
    "    loss_type: LossType = LossType.TOPK\n",
    "    # training \n",
    "    batch_size: int = 32\n",
    "    target_batch_size: int = 64\n",
    "    epochs: int = 5\n",
    "    heads: int = 2\n",
    "    binary: bool = False\n",
    "    model: str = \"Resnet50\"\n",
    "    shared_backbone: bool = True\n",
    "    source_weight: float = 1.0\n",
    "    aux_weight: float = 1.0\n",
    "    use_group_labels: bool = False\n",
    "    freeze_heads: bool = False\n",
    "    head_1_epochs: int = 5\n",
    "    # dataset\n",
    "    source_cc: bool = True\n",
    "    source_val_split: float = 0.2\n",
    "    target_val_split: float = 0.2\n",
    "    mix_rate: Optional[float] = 0.5\n",
    "    shuffle_target: bool = True\n",
    "    dataset_length: Optional[int] = None\n",
    "    max_length: int = 128  # for text datasets\n",
    "    combine_neut_entail: bool = False # for multi-nli\n",
    "    contra_no_neg: bool = True # for multi-nli\n",
    "    # topk # TODO: generalize properly configure group mix rates for MLI\n",
    "    aggregate_mix_rate: bool = True\n",
    "    mix_rate_lower_bound: Optional[float] = 0.5\n",
    "    mix_rate_lower_bound_01: Optional[float] = None\n",
    "    mix_rate_lower_bound_10: Optional[float] = None\n",
    "    group_mix_rate_lower_bounds: Optional[dict[str, float]] = None # field(default_factory=lambda: {\"0_1\": 0.1, \"1_0\": 0.1})\n",
    "    disagree_only: bool = True\n",
    "    mix_rate_schedule: Optional[str] = \"linear\"\n",
    "    mix_rate_t0: Optional[int] = 0\n",
    "    mix_rate_t1: Optional[int] = 5\n",
    "    mix_rate_interval_frac: Optional[float] = None # for mix rate updates within epoch\n",
    "    # optimizer \n",
    "    lr: float = 1e-4\n",
    "    weight_decay: float = 1e-3 # 1e-4\n",
    "    optimizer: str = \"adamw\"\n",
    "    lr_scheduler: Optional[str] = None \n",
    "    num_cycles: float = 0.5\n",
    "    frac_warmup: float = 0.05\n",
    "    # misc\n",
    "    num_workers: int = 4\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    exp_dir: str = f\"output/{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "    plot_activations: bool = False\n",
    "\n",
    "def str_to_tuple(s: str) -> tuple[int, ...]:\n",
    "    return tuple(int(i) for i in s.split(\"_\"))\n",
    "\n",
    "def post_init(conf: Config, overrides: list[str]=[]):\n",
    "    if conf.freeze_heads and \"head_1_epochs\" not in overrides:\n",
    "        conf.head_1_epochs = round(conf.epochs / 2)\n",
    "    \n",
    "    # set group mix rate lower bounds based on 01 10 (kinda hacky for doing hparam searches)\n",
    "    if conf.mix_rate_lower_bound_01 is not None or conf.mix_rate_lower_bound_10 is not None:\n",
    "        assert conf.group_mix_rate_lower_bounds is None\n",
    "        conf.group_mix_rate_lower_bounds = {\n",
    "            \"0_1\": conf.mix_rate_lower_bound_01 if conf.mix_rate_lower_bound_01 is not None else 0,\n",
    "            \"1_0\": conf.mix_rate_lower_bound_10 if conf.mix_rate_lower_bound_10 is not None else 0,\n",
    "        }\n",
    "    \n",
    "    if conf.group_mix_rate_lower_bounds is not None:\n",
    "        conf.group_mix_rate_lower_bounds = {str_to_tuple(k): v for k, v in conf.group_mix_rate_lower_bounds.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if conf.dataset in [\"waterbirds\", \"celebA-0\", \"celebA-1\", \"celebA-2\", \"toy_grid\"]:\n",
    "#     if conf.loss_type == LossType.TOPK and conf.mix_rate_lower_bound == 0.1:\n",
    "#         conf.aux_weight = 7.0 \n",
    "#     else:\n",
    "#         conf.aux_weight = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf.dataset = \"toy_grid\"\n",
    "# conf.lr = 1e-3\n",
    "# conf.optimizer = \"adamw\"\n",
    "# conf.model = \"toy_model\"\n",
    "# conf.batch_size = 32 \n",
    "# conf.target_batch_size = 128\n",
    "# conf.epochs = 100\n",
    "# conf.loss_type = LossType.DIVDIS\n",
    "# conf.mix_rate_lower_bound = 0.5\n",
    "# conf.plot_activations = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if conf.loss_type == LossType.DBAT:\n",
    "#     conf.shared_backbone = False \n",
    "#     conf.freeze_heads = True\n",
    "#     conf.batch_size = 16\n",
    "#     conf.target_batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if conf.dataset in [\"waterbirds\", \"cub\"] and conf.loss_type == LossType.DIVDIS:\n",
    "#     conf.lr = 1e-3\n",
    "#     conf.weight_decay = 1e-4\n",
    "#     conf.epochs = 100\n",
    "#     conf.optimizer = \"sgd\"\n",
    "#     conf.batch_size = 16 \n",
    "#     conf.target_batch_size = 16\n",
    "#     conf.aux_weight = 10.0\n",
    "#     conf.shuffle_target = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if conf.dataset == \"waterbirds\" and conf.loss_type == LossType.TOPK:\n",
    "#     conf.optimizer = \"sgd\"\n",
    "#     conf.target_01_mix_rate_lower_bound = 0.38\n",
    "#     conf.target_10_mix_rate_lower_bound = 0.10\n",
    "#     conf.mix_rate_lower_bound = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # toy grid configs \n",
    "# if conf.dataset == \"toy_grid\":\n",
    "#     conf.model = \"toy_model\"\n",
    "#     conf.epochs = 128\n",
    "# if conf.model == \"ClipViT\":\n",
    "#     # conf.epochs = 5\n",
    "#     conf.lr = 1e-5\n",
    "# Resnet50 Configs\n",
    "# if conf.model == \"Resnet50\":\n",
    "#     conf.lr = 1e-4 # probably too high, should be 1e-4\n",
    "# if conf.dataset == \"multi-nli\" or conf.dataset == \"civil_comments\":\n",
    "#     conf.model = \"bert\"\n",
    "#     conf.lr = 1e-5\n",
    "#     conf.lr_scheduler = \"cosine\"\n",
    "#     conf.combine_neut_entail = True\n",
    "#     conf.contra_no_neg = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get config overrides if runnign from command line\n",
    "overrride_keys = []\n",
    "if not is_notebook():\n",
    "    import sys \n",
    "    overrides = OmegaConf.from_cli(sys.argv[1:])\n",
    "    overrride_keys = overrides.keys()\n",
    "    conf_dict = OmegaConf.merge(OmegaConf.structured(conf), overrides)\n",
    "    conf = Config(**conf_dict)\n",
    "\n",
    "exp_dir = conf.exp_dir\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "# save full config to exp_dir\n",
    "with open(f\"{exp_dir}/config.yaml\", \"w\") as f:\n",
    "    OmegaConf.save(config=conf, f=f)\n",
    "post_init(conf, overrride_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf.heads != 2:\n",
    "    raise ValueError(\"Only 2 heads currently supported\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(conf.seed)\n",
    "np.random.seed(conf.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transform = None\n",
    "pad_sides = False\n",
    "tokenizer = None\n",
    "if conf.model == \"Resnet50\":\n",
    "    from torchvision import models\n",
    "    from torchvision.models.resnet import ResNet50_Weights\n",
    "    resnet_builder = lambda: models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)    \n",
    "    model_builder = lambda: torch.nn.Sequential(*list(resnet_builder().children())[:-1])\n",
    "    resnet_50_transforms = ResNet50_Weights.IMAGENET1K_V1.transforms()\n",
    "    model_transform = transforms.Compose([\n",
    "        transforms.Resize(resnet_50_transforms.resize_size * 2, interpolation=resnet_50_transforms.interpolation),\n",
    "        transforms.CenterCrop(resnet_50_transforms.crop_size),\n",
    "        transforms.Normalize(mean=resnet_50_transforms.mean, std=resnet_50_transforms.std)\n",
    "    ])\n",
    "    pad_sides = True\n",
    "    feature_dim = 2048\n",
    "elif conf.model == \"ClipViT\":\n",
    "    # from models.clip_vit import ClipViT\n",
    "    # model_builder = lambda: ClipViT()\n",
    "    # feature_dim = 768\n",
    "    # input_size = 96\n",
    "    # model_transform = transforms.Compose([\n",
    "    #     transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BICUBIC)\n",
    "    # ])\n",
    "    import clip \n",
    "    preprocess = clip.clip._transform(224)\n",
    "    clip_builder = lambda: clip.load('ViT-B/32', device='cpu')[0]\n",
    "    model_builder = lambda: clip_builder().visual\n",
    "    model_transform = transforms.Compose([\n",
    "        preprocess.transforms[0],\n",
    "        preprocess.transforms[1],\n",
    "        preprocess.transforms[4]\n",
    "    ])\n",
    "    feature_dim = 512\n",
    "    pad_sides = True\n",
    "elif conf.model == \"bert\":\n",
    "    from transformers import BertModel, BertTokenizer\n",
    "    from models.hf_wrapper import HFWrapper\n",
    "    bert_builder = lambda: BertModel.from_pretrained('bert-base-uncased')\n",
    "    model_builder = lambda: HFWrapper(bert_builder())\n",
    "    feature_dim = 768\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "elif conf.model == \"toy_model\":\n",
    "    model_builder = lambda: nn.Sequential(\n",
    "        nn.Linear(2, 40), nn.ReLU(), nn.Linear(40, 40), nn.ReLU()\n",
    "    )\n",
    "    feature_dim = 40\n",
    "elif conf.model == \"LeNet\":\n",
    "    from models.lenet import LeNet\n",
    "    from functools import partial\n",
    "    model_builder = lambda: partial(LeNet, num_classes=1, dropout_p=0.0)\n",
    "    feature_dim = 256\n",
    "else: \n",
    "    raise ValueError(f\"Model {conf.model} not supported\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = None\n",
    "# TODO: there should be varaible n_classes for each feature \n",
    "classes_per_head = [2, 2]\n",
    "classes_per_feat = [2, 2]\n",
    "is_img = True\n",
    "alt_index = 1\n",
    "\n",
    "if conf.dataset == \"toy_grid\":\n",
    "    source_train, source_val, target_train, target_val, target_test = get_toy_grid_datasets(\n",
    "        target_mix_rate_0_1=conf.mix_rate / 2 if conf.mix_rate is not None else None, \n",
    "        target_mix_rate_1_0=conf.mix_rate / 2 if conf.mix_rate is not None else None, \n",
    "        gaussian=True,\n",
    "        std=0.01\n",
    "    )\n",
    "elif conf.dataset == \"cifar_mnist\":\n",
    "    source_train, source_val, target_train, target_val, target_test = get_cifar_mnist_datasets(\n",
    "        target_mix_rate_0_1=conf.mix_rate / 2 if conf.mix_rate is not None else None, \n",
    "        target_mix_rate_1_0=conf.mix_rate / 2 if conf.mix_rate is not None else None, \n",
    "        transform=model_transform, \n",
    "        pad_sides=pad_sides\n",
    "    )\n",
    "\n",
    "elif conf.dataset == \"fmnist_mnist\":\n",
    "    source_train, source_val, target_train, target_val, target_test = get_fmnist_mnist_datasets(\n",
    "        target_mix_rate_0_1=conf.mix_rate / 2 if conf.mix_rate is not None else None, \n",
    "        target_mix_rate_1_0=conf.mix_rate / 2 if conf.mix_rate is not None else None, \n",
    "        transform=model_transform, \n",
    "        pad_sides=pad_sides\n",
    "    )\n",
    "elif conf.dataset == \"waterbirds\":\n",
    "    source_train, source_val, target_train, target_val, target_test = get_waterbirds_datasets(\n",
    "        mix_rate=conf.mix_rate, \n",
    "        source_cc=conf.source_cc,\n",
    "        transform=model_transform, \n",
    "        convert_to_tensor=True,\n",
    "        val_split=conf.source_val_split,\n",
    "        target_val_split=conf.target_val_split, \n",
    "        dataset_length=conf.dataset_length\n",
    "    )\n",
    "# elif conf.dataset == \"cub\":\n",
    "#     source_train, target_train, target_test = get_cub_datasets()\n",
    "#     source_val = []\n",
    "#     target_val = []\n",
    "elif conf.dataset.startswith(\"celebA\"):\n",
    "    if conf.dataset == \"celebA-0\":\n",
    "        gt_feat = \"Blond_Hair\"\n",
    "        spur_feat = \"Male\"\n",
    "        inv_spur_feat = True\n",
    "    elif conf.dataset == \"celebA-1\":\n",
    "        gt_feat = \"Mouth_Slightly_Open\"\n",
    "        spur_feat = \"Wearing_Lipstick\"\n",
    "        inv_spur_feat = False\n",
    "    elif conf.dataset == \"celebA-2\":\n",
    "        gt_feat = \"Wavy_Hair\"\n",
    "        spur_feat = \"High_Cheekbones\"\n",
    "        inv_spur_feat = False\n",
    "    else: \n",
    "        raise ValueError(f\"Dataset {conf.dataset} not supported\")\n",
    "    source_train, source_val, target_train, target_val, target_test = get_celebA_datasets(\n",
    "        mix_rate=conf.mix_rate, \n",
    "        source_cc=conf.source_cc,\n",
    "        transform=model_transform, \n",
    "        gt_feat=gt_feat,\n",
    "        spur_feat=spur_feat,\n",
    "        inv_spur_feat=inv_spur_feat,\n",
    "        dataset_length=conf.dataset_length\n",
    "    )\n",
    "elif conf.dataset == \"camelyon\":\n",
    "    source_train, source_val, target_train, target_val, target_test = get_camelyon_datasets(\n",
    "        transform=model_transform, \n",
    "        dataset_length=conf.dataset_length\n",
    "    )\n",
    "# elif conf.dataset == \"civil_comments\":\n",
    "#     source_train, source_val, target_train, target_val, target_test = get_civil_comments_datasets(\n",
    "#         tokenizer=tokenizer,\n",
    "#         max_length=conf.max_length, \n",
    "#         dataset_length=conf.dataset_length\n",
    "#     )\n",
    "#     is_img = False\n",
    "\n",
    "elif conf.dataset == \"multi-nli\":\n",
    "    source_train, source_val, target_train, target_val, target_test = get_multi_nli_datasets(\n",
    "        mix_rate=conf.mix_rate,\n",
    "        source_cc=conf.source_cc,\n",
    "        val_split=conf.source_val_split,\n",
    "        target_val_split=conf.target_val_split,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=conf.max_length, \n",
    "        dataset_length=conf.dataset_length, \n",
    "        combine_neut_entail=conf.combine_neut_entail, \n",
    "        contra_no_neg=conf.contra_no_neg\n",
    "    )\n",
    "    is_img = False\n",
    "    if not conf.combine_neut_entail:\n",
    "        classes_per_feat = [3, 2]\n",
    "        if conf.use_group_labels:\n",
    "            classes_per_head = [3, 2] # [contradiction, entailment, neutral] x [no negation, negation]\n",
    "        else:\n",
    "            classes_per_head = [3, 3] # [contradiction, entailment, neutral] x 2\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Dataset {conf.dataset} not supported\")\n",
    "\n",
    "assert len(classes_per_head) == conf.heads\n",
    "if conf.binary:\n",
    "    assert all([c == 2 for c in classes_per_head])\n",
    "    classes_per_head = [1 for c in classes_per_head]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_count(df, i, j):\n",
    "#     try: \n",
    "#         return df.value_counts()[i][j]\n",
    "#     except KeyError: \n",
    "#         return 0\n",
    "\n",
    "# gl_df = pd.DataFrame(target_train.dataset.feature_labels[target_train.indices])\n",
    "\n",
    "# counts_00 = get_count(gl_df, 0, 0)\n",
    "# counts_01 = get_count(gl_df, 0, 1)\n",
    "# counts_10 = get_count(gl_df, 1, 0)\n",
    "# counts_11 = get_count(gl_df, 1, 1)\n",
    "\n",
    "# y0_freq = (counts_00 + counts_01) / (counts_00 + counts_01 + counts_10 + counts_11)\n",
    "# a0_freq = (counts_00 + counts_10) / (counts_00 + counts_01 + counts_10 + counts_11)\n",
    "\n",
    "# print(f\"y0_freq: {y0_freq}, a0_freq: {a0_freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot image \n",
    "img, y, gl = source_train[-1]\n",
    "# pad \n",
    "# to PIL image \n",
    "\n",
    "# img = transforms.ToPILImage()(img)\n",
    "# img\n",
    "if is_img and img.dim() == 3 and is_notebook():\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "    # show without axis \n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot target train images with vision_utils.make_grid\n",
    "if is_img and img.dim() == 3 and is_notebook():\n",
    "    img_tensor_grid = torch.stack([target_train[i][0] for i in range(20)])\n",
    "    grid_img = vision_utils.make_grid(img_tensor_grid, nrow=10, normalize=True, padding=1)\n",
    "    plt.imshow(grid_img.permute(1, 2, 0))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DivisibleBatchSampler(torch.utils.data.Sampler):\n",
    "    def __init__(self, dataset_size: int, batch_size: int, shuffle: bool = True):\n",
    "        self.dataset_size = dataset_size\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.rng = rnd.Random(42)\n",
    "        \n",
    "        # Calculate number of complete batches and total samples needed\n",
    "        self.num_batches = math.ceil(dataset_size / batch_size)\n",
    "        self.total_size = self.num_batches * batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Generate indices for the entire dataset\n",
    "        indices = list(range(self.dataset_size))\n",
    "        \n",
    "        if self.shuffle:\n",
    "            # Shuffle all indices\n",
    "            self.rng.shuffle(indices)\n",
    "            \n",
    "        # If we need more indices to make complete batches,\n",
    "        # randomly sample from existing indices\n",
    "        if self.total_size > self.dataset_size:\n",
    "            extra_indices = self.rng.choices(indices, k=self.total_size - self.dataset_size)\n",
    "            indices.extend(extra_indices)\n",
    "            \n",
    "        assert len(indices) == self.total_size\n",
    "        return iter(indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_train_loader = DataLoader(\n",
    "    source_train, batch_size=conf.batch_size, num_workers=conf.num_workers, \n",
    "    sampler=DivisibleBatchSampler(len(source_train), conf.batch_size, shuffle=True), \n",
    ")\n",
    "if len(source_val) > 0:\n",
    "    source_val_loader = DataLoader(\n",
    "        source_val, batch_size=conf.batch_size, num_workers=conf.num_workers, \n",
    "        sampler=DivisibleBatchSampler(len(source_val), conf.batch_size, shuffle=False)\n",
    "    )\n",
    "# NOTE: shuffle \"should\" be true, but in divdis code its false, and this leads to substantial changes in worst goup result\n",
    "target_train_loader = DataLoader(\n",
    "    target_train, batch_size=conf.target_batch_size, num_workers=conf.num_workers, \n",
    "    sampler=DivisibleBatchSampler(len(target_train), conf.target_batch_size, shuffle=conf.shuffle_target)\n",
    ")\n",
    "if len(target_val) > 0:\n",
    "    target_val_loader = DataLoader(\n",
    "        target_val, batch_size=conf.target_batch_size, num_workers=conf.num_workers, \n",
    "        sampler=DivisibleBatchSampler(len(target_val), conf.target_batch_size, shuffle=False)\n",
    "    )\n",
    "target_test_loader = DataLoader(\n",
    "    target_test, batch_size=conf.batch_size, num_workers=conf.num_workers, shuffle=False\n",
    ")\n",
    "\n",
    "# classifiers\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "if conf.shared_backbone:\n",
    "    net = MultiHeadBackbone(model_builder(), classes_per_head, feature_dim)\n",
    "else:\n",
    "    net = MultiNetModel(model_builder=model_builder, classes_per_head=classes_per_head, feature_dim=feature_dim)\n",
    "net = net.to(conf.device)\n",
    "\n",
    "# optimizer\n",
    "if conf.optimizer == \"adamw\":\n",
    "    opt = torch.optim.AdamW(net.parameters(), lr=conf.lr, weight_decay=conf.weight_decay)\n",
    "elif conf.optimizer == \"sgd\":\n",
    "    opt = torch.optim.SGD(net.parameters(), lr=conf.lr, weight_decay=conf.weight_decay, momentum=0.9)\n",
    "else: \n",
    "    raise ValueError(f\"Optimizer {conf.optimizer} not supported\")\n",
    "num_steps = conf.epochs * len(source_train_loader)\n",
    "if conf.lr_scheduler == \"cosine\":       \n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        opt, \n",
    "        num_warmup_steps=num_steps * conf.frac_warmup, \n",
    "        num_training_steps=num_steps, \n",
    "        num_cycles=conf.num_cycles\n",
    "    )\n",
    "else: \n",
    "    # constant learning rate\n",
    "    scheduler = None\n",
    "\n",
    "\n",
    "# loss function\n",
    "if conf.loss_type == LossType.DIVDIS:\n",
    "    loss_fn = DivDisLoss(heads=conf.heads)\n",
    "elif conf.loss_type == LossType.DBAT:\n",
    "    loss_fn = DBatLoss(heads=conf.heads, n_classes=classes_per_head[0])\n",
    "elif conf.loss_type == LossType.CONF:\n",
    "    loss_fn = ConfLoss()\n",
    "elif conf.loss_type == LossType.SMOOTH:\n",
    "    loss_fn = SmoothTopLoss(\n",
    "        criterion=partial(F.binary_cross_entropy_with_logits, reduction='none'), \n",
    "        device=conf.device\n",
    "    )\n",
    "elif conf.loss_type == LossType.ERM:\n",
    "    loss_fn = PassThroughLoss()\n",
    "elif conf.loss_type in [LossType.TOPK, LossType.EXP, LossType.PROB]:\n",
    "    def get_mix_rate(conf, mix_rate_lb_override=None, group_mix_rate_lb_override=None):\n",
    "        mix_rate_lower_bound = mix_rate_lb_override if mix_rate_lb_override is not None else conf.mix_rate_lower_bound\n",
    "        group_mix_rate_lower_bounds = group_mix_rate_lb_override if group_mix_rate_lb_override is not None else conf.group_mix_rate_lower_bounds\n",
    "        if conf.aggregate_mix_rate:\n",
    "            mix_rate = mix_rate_lower_bound\n",
    "            group_mix_rates = None\n",
    "        elif conf.group_mix_rate_lower_bounds is not None:\n",
    "            mix_rate = None \n",
    "            group_mix_rates = group_mix_rate_lower_bounds\n",
    "        else:\n",
    "            mix_rate = None \n",
    "            if conf.dataset == \"multi-nli\" and conf.use_group_labels:\n",
    "                ood_groups = [(0, 1), (1, 0), (2, 0)]\n",
    "            else: \n",
    "                mix_rate_cls_per_head = classes_per_head \n",
    "                if conf.binary:\n",
    "                    mix_rate_cls_per_head = [2 for _ in classes_per_head]\n",
    "                ood_groups = [gl for gl in feature_label_ls(mix_rate_cls_per_head)\n",
    "                            if any(gl[0] != gl[i] for i in range(1, len(gl)))]\n",
    "            group_mix_rates = {group: mix_rate_lower_bound / len(ood_groups) for group in ood_groups}\n",
    "        return mix_rate, group_mix_rates\n",
    "    \n",
    "    mix_rate, group_mix_rates = get_mix_rate(conf)\n",
    "\n",
    "    loss_fn = ACELoss(\n",
    "        classes_per_head=classes_per_head,\n",
    "        mode=conf.loss_type.value, \n",
    "        mix_rate=mix_rate,\n",
    "        group_mix_rates=group_mix_rates,\n",
    "        disagree_only=conf.disagree_only,\n",
    "        device=conf.device\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Loss type {conf.loss_type} not supported\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize data using first two principle componets of final layer activations\n",
    "if conf.plot_activations and conf.shared_backbone:\n",
    "    model = model_builder()\n",
    "    model = model.to(conf.device)\n",
    "    test_acts, test_labels = get_acts_and_labels(model, target_test_loader, conf.device)\n",
    "    test_labels = test_labels.to('cpu')\n",
    "    pca_fig, pca_acts, pca_reducer = plot_activations(\n",
    "        activations=test_acts, labels=test_labels, \n",
    "        classes_per_feature=classes_per_feat, transform=\"pca\"\n",
    "    )\n",
    "    umap_fig, umap_acts, umap_reducer = plot_activations(\n",
    "        activations=test_acts, labels=test_labels, \n",
    "        classes_per_feature=classes_per_feat, transform=\"umap\"\n",
    "    )\n",
    "    pca_fig.savefig(f\"{exp_dir}/activations_pretrain_pca.png\")\n",
    "    pca_fig.savefig(f\"{exp_dir}/activations_pretrain_pca.svg\")\n",
    "    umap_fig.savefig(f\"{exp_dir}/activations_pretrain_umap.png\")\n",
    "    umap_fig.savefig(f\"{exp_dir}/activations_pretrain_umap.svg\")\n",
    "    np.save(f\"{exp_dir}/activations_pretrain_pca.npy\", pca_acts)\n",
    "    np.save(f\"{exp_dir}/activations_pretrain_umap.npy\", umap_acts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit linear probe \n",
    "if conf.plot_activations and conf.shared_backbone:\n",
    "    train_acts, train_labels = get_acts_and_labels(model, target_train_loader, conf.device)\n",
    "    probe_acc, probe_acc_alt = compute_probe_acc(train_acts, train_labels, test_acts, test_labels, classes_per_feat)\n",
    "    print(f\"Accuracy: {probe_acc:.4f}\")\n",
    "    print(f\"Alt Accuracy: {probe_acc_alt:.4f}\")\n",
    "    # nah I'll just try to picke the umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_src_losses(logits, y, gl):\n",
    "    logits_by_head = torch.split(logits, classes_per_head, dim=-1)\n",
    "    labels_by_head = [y, y] if not conf.use_group_labels else [gl[:, 0], gl[:, 1]]\n",
    "\n",
    "    if conf.binary: # NOTE: not currently supported\n",
    "        losses = [F.binary_cross_entropy_with_logits(logit.squeeze(), y.squeeze().to(torch.float32)) \n",
    "                  for logit, y in zip(logits_by_head, labels_by_head)]\n",
    "    else:\n",
    "        assert logits_by_head[0].shape == (logits.size(0), classes_per_head[0]), logits_by_head[0].shape\n",
    "        losses = [F.cross_entropy(logit.squeeze(), y.squeeze().to(torch.long)) \n",
    "                  for logit, y in zip(logits_by_head, labels_by_head)]\n",
    "    return losses\n",
    "\n",
    "# TODO: fix\n",
    "def compute_corrects(logits: torch.Tensor, y: torch.Tensor, binary: bool):\n",
    "    if binary: # NOTE: not currently supported\n",
    "        return ((logits.squeeze() > 0) == y.flatten()).sum().item()\n",
    "    else:\n",
    "        return (logits.argmax(dim=-1) == y).sum().item()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, loader, device, loss_fn, use_labels=False, stage: str = \"Evaluating\"): \n",
    "    group_label_ls = feature_label_ls(classes_per_feat)\n",
    "    # e.g. for classes per_head = [3,2]\n",
    "    # group_label_ls = [(0, 0), (0, 1), (1, 0), (1, 1), (2, 0), (2, 1)]\n",
    "    \n",
    "    # loss \n",
    "    losses = []\n",
    "\n",
    "    # accuracy \n",
    "    total_corrects_by_groups = {\n",
    "        group_label: torch.zeros(conf.heads)\n",
    "        for group_label in group_label_ls\n",
    "    }\n",
    "    total_corrects_alt_by_groups = {\n",
    "        group_label: torch.zeros(conf.heads)\n",
    "        for group_label in group_label_ls\n",
    "    }\n",
    "    total_samples = 0\n",
    "    total_samples_by_groups = {\n",
    "        group_label: 0\n",
    "        for group_label in group_label_ls\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y, gl in tqdm(loader, desc=stage):\n",
    "            x, y, gl = to_device(x, y, gl, conf.device)\n",
    "            logits = model(x)\n",
    "            # print(test_logits.shape)\n",
    "            total_samples += logits.size(0)\n",
    "            if use_labels and loss_fn is not None:\n",
    "                loss = loss_fn(logits, y, gl)\n",
    "            elif loss_fn is not None:\n",
    "                loss = loss_fn(logits)\n",
    "            else: \n",
    "                loss = torch.tensor(0.0, device=conf.device)\n",
    "            if torch.isnan(loss):\n",
    "                print(f\"Warning: Nan Loss (likely due to batch size and target loss) \"\n",
    "                f\"Batch size: {logits.size(0)}, Loss: {conf.loss_type}\")\n",
    "            else:\n",
    "                losses.append(loss)\n",
    "\n",
    "            # parition instances into groups based on group labels \n",
    "            logits_by_group = {}\n",
    "            for group_label in group_label_ls:\n",
    "                group_label_mask = torch.all(gl == torch.tensor(group_label).to(device), dim=1)\n",
    "                # print(\"group label mask\", group_label_mask.shape)\n",
    "                logits_by_group[group_label] = logits[group_label_mask]\n",
    "            # print(\"group logit shapes\", [v.shape for v in logits_by_group.values()])\n",
    "            \n",
    "            for group_label, group_logits in logits_by_group.items():\n",
    "                num_examples_group = group_logits.size(0)\n",
    "                total_samples_by_groups[group_label] += num_examples_group\n",
    "                group_labels = torch.tensor(group_label).repeat(num_examples_group, 1).to(device)\n",
    "                group_logits_by_head = torch.split(group_logits, classes_per_head, dim=-1)\n",
    "                for i in range(conf.heads):\n",
    "                    if conf.use_group_labels:\n",
    "                        total_corrects_by_groups[group_label][i] += compute_corrects(group_logits_by_head[i], group_labels[:, i], conf.binary)\n",
    "                    else:\n",
    "                        total_corrects_by_groups[group_label][i] += compute_corrects(group_logits_by_head[i], group_labels[:, 0], conf.binary)\n",
    "                        total_corrects_alt_by_groups[group_label][i] += compute_corrects(group_logits_by_head[i], group_labels[:, 1], conf.binary)\n",
    "    \n",
    "    total_corrects = torch.stack([gl_corrects for gl_corrects in total_corrects_by_groups.values()], dim=0).sum(dim=0)\n",
    "    if not conf.use_group_labels:\n",
    "        total_corrects_alt = torch.stack([gl_corrects for gl_corrects in total_corrects_alt_by_groups.values()], dim=0).sum(dim=0)\n",
    "\n",
    "    # average metrics\n",
    "    metrics = {}\n",
    "    for i in range(conf.heads):\n",
    "        metrics[f\"acc_{i}\"] = (total_corrects[i] / total_samples).item()\n",
    "        if not conf.use_group_labels:\n",
    "            metrics[f\"acc_alt_{i}\"] = (total_corrects_alt[i] / total_samples).item()\n",
    "    \n",
    "    if loss_fn is not None:\n",
    "        metrics[\"loss\"] = torch.mean(torch.tensor(losses)).item()\n",
    "    # group acc per head\n",
    "    for group_label in group_label_ls:\n",
    "        for i in range(conf.heads): \n",
    "            metrics[f\"acc_{i}_{group_label}\"] = (total_corrects_by_groups[group_label][i] / total_samples_by_groups[group_label]).item()\n",
    "            if not conf.use_group_labels:\n",
    "                metrics[f\"acc_alt_{i}_{group_label}\"] = (total_corrects_alt_by_groups[group_label][i] / total_samples_by_groups[group_label]).item()\n",
    "    # worst group acc per head\n",
    "    for i in range(conf.heads):\n",
    "        metrics[f\"worst_acc_{i}\"] = min([metrics[f\"acc_{i}_{group_label}\"] for group_label in group_label_ls])\n",
    "\n",
    "    # add group counts \n",
    "    for group_label in group_label_ls:\n",
    "        metrics[f\"count_{group_label}\"] = total_samples_by_groups[group_label]\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(exp_dir)\n",
    "if conf.plot_activations and conf.shared_backbone:   \n",
    "    logger.add_scalar(\"test\", \"probe_acc\", probe_acc, -1)\n",
    "    logger.add_scalar(\"test\", \"probe_acc_alt\", probe_acc_alt, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "valid_loss_fn = loss_fn \n",
    "if isinstance(loss_fn, ACELoss) and conf.mix_rate_schedule is not None:\n",
    "    print('hello')\n",
    "    valid_loss_fn = copy.deepcopy(loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cur_mix_rate(conf, epoch): \n",
    "    cur_mix_rate = None\n",
    "    cur_group_mix_rates = None\n",
    "    if epoch < conf.mix_rate_t0: # set to 0\n",
    "        if conf.mix_rate_lower_bound is not None:\n",
    "            cur_mix_rate = 0 \n",
    "        if conf.group_mix_rate_lower_bounds is not None:\n",
    "            cur_group_mix_rates = {group: 0 for group in conf.group_mix_rate_lower_bounds.keys()}\n",
    "    elif epoch >= conf.mix_rate_t1: # set to lower bound\n",
    "        if conf.mix_rate_lower_bound is not None:\n",
    "            cur_mix_rate = conf.mix_rate_lower_bound\n",
    "        if conf.group_mix_rate_lower_bounds is not None:\n",
    "            cur_group_mix_rates = {group: conf.group_mix_rate_lower_bounds[group] for group in conf.group_mix_rate_lower_bounds.keys()}\n",
    "    else: # set to linear schedule\n",
    "        if conf.mix_rate_lower_bound is not None:\n",
    "            cur_mix_rate = conf.mix_rate_lower_bound * (epoch - conf.mix_rate_t0) / (conf.mix_rate_t1 - conf.mix_rate_t0)\n",
    "        if conf.group_mix_rate_lower_bounds is not None:\n",
    "            cur_group_mix_rates = {group: conf.group_mix_rate_lower_bounds[group] * (epoch - conf.mix_rate_t0) / (conf.mix_rate_t1 - conf.mix_rate_t0) for group in conf.group_mix_rate_lower_bounds.keys()}\n",
    "    return cur_mix_rate, cur_group_mix_rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change diciotary values to source loss, target loss\n",
    "from itertools import cycle\n",
    "try:\n",
    "    if conf.freeze_heads:\n",
    "        # freeze first head (for dbat)\n",
    "        net.freeze_head(0)\n",
    "    total_steps = 0\n",
    "    for epoch in range(conf.epochs):\n",
    "        train_loader = zip(source_train_loader, cycle(target_train_loader))\n",
    "        loader_len = len(source_train_loader)\n",
    "        ### Train\n",
    "        # mix rate schedule \n",
    "        if isinstance(loss_fn, ACELoss):\n",
    "            if conf.mix_rate_schedule == \"linear\" and conf.mix_rate_interval_frac is None:\n",
    "                cur_mix_rate, cur_group_mix_rates = get_cur_mix_rate(conf, epoch)\n",
    "                mix_rate, group_mix_rates = get_mix_rate(conf, mix_rate_lb_override=cur_mix_rate, group_mix_rate_lb_override=cur_group_mix_rates)\n",
    "                loss_fn.mix_rate = mix_rate\n",
    "                loss_fn.group_mix_rates = group_mix_rates\n",
    "        \n",
    "        for batch_idx, (source_batch, target_batch) in tqdm(enumerate(train_loader), desc=\"Source train\", total=loader_len):\n",
    "            # update mix rate schedule\n",
    "            if isinstance(loss_fn, ACELoss):\n",
    "                if conf.mix_rate_schedule == \"linear\" and conf.mix_rate_interval_frac is not None:\n",
    "                    if total_steps % int(num_steps * conf.mix_rate_interval_frac) == 0:\n",
    "                        cur_mix_rate = conf.mix_rate_lower_bound * (total_steps / num_steps) if conf.mix_rate_lower_bound is not None else None\n",
    "                        cur_group_mix_rates = {group: conf.group_mix_rate_lower_bounds[group] * (total_steps / num_steps) for group in conf.group_mix_rate_lower_bounds.keys()} if conf.group_mix_rate_lower_bounds is not None else None\n",
    "                        mix_rate, group_mix_rates = get_mix_rate(conf, mix_rate_lb_override=cur_mix_rate, group_mix_rate_lb_override=cur_group_mix_rates)\n",
    "                        print(\"updating mix rate\", \"steps\", total_steps, \"mix rate\", cur_mix_rate)\n",
    "                        loss_fn.mix_rate = mix_rate\n",
    "                        loss_fn.group_mix_rates = group_mix_rates\n",
    "            # freeze heads for dbat\n",
    "            if conf.freeze_heads and epoch == conf.head_1_epochs: \n",
    "                net.unfreeze_head(0)\n",
    "                net.freeze_head(1)\n",
    "            # source\n",
    "            x, y, gl = to_device(*source_batch, conf.device)\n",
    "            logits = net(x)\n",
    "            losses = compute_src_losses(logits, y, gl)\n",
    "            xent = torch.mean(torch.stack(losses))\n",
    "            logger.add_scalar(\"train\", \"source_loss\", xent.item(), epoch * loader_len + batch_idx)\n",
    "            \n",
    "            # target\n",
    "            target_x, target_y, target_gl = to_device(*target_batch, conf.device)\n",
    "            target_logits = net(target_x)\n",
    "            target_loss = loss_fn(target_logits)           \n",
    "            \n",
    "            logger.add_scalar(\"train\", \"target_loss\", target_loss.item(), epoch * loader_len + batch_idx)\n",
    "            logger.add_scalar(\"train\", \"weighted_target_loss\", conf.aux_weight * target_loss.item(), epoch * loader_len + batch_idx, to_metrics=False, to_tb=True)\n",
    "            # don't compute target loss before second head begins training\n",
    "            if conf.freeze_heads and epoch < conf.head_1_epochs: \n",
    "                target_loss = torch.tensor(0.0, device=conf.device)\n",
    "            \n",
    "            # full loss \n",
    "            full_loss = conf.source_weight * xent + conf.aux_weight * target_loss\n",
    "            logger.add_scalar(\"train\", \"loss\", full_loss.item(), epoch * loader_len + batch_idx)\n",
    "            \n",
    "            # backprop\n",
    "            opt.zero_grad()\n",
    "            full_loss.backward()\n",
    "            opt.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            total_steps += 1\n",
    "        \n",
    "        # eval\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            net.eval()\n",
    "            ### Validation \n",
    "           \n",
    "            # source\n",
    "            total_val_loss = 0.0\n",
    "            total_val_weighted_loss = 0.0\n",
    "            if len(source_val) > 0:\n",
    "                src_loss_fn = lambda x, y, gl: sum(compute_src_losses(x, y, gl))\n",
    "                source_val_metrics = eval(net, source_val_loader, conf.device, src_loss_fn, use_labels=True, stage=\"Source Val\")\n",
    "                for k, v in source_val_metrics.items():\n",
    "                    if 'count' not in k:\n",
    "                        logger.add_scalar(\"val\", f\"source_{k}\", v, epoch)\n",
    "                total_val_loss += source_val_metrics[\"loss\"]\n",
    "                total_val_weighted_loss += total_val_loss\n",
    "            # target\n",
    "            weighted_target_val_loss = 0.0\n",
    "            if len(target_val) > 0:  \n",
    "                target_val_metrics = eval(net, target_val_loader, conf.device, valid_loss_fn, use_labels=False, stage=\"Target Val\")\n",
    "                for k, v in target_val_metrics.items():\n",
    "                    if 'count' not in k:\n",
    "                        logger.add_scalar(\"val\", f\"target_{k}\", v, epoch)\n",
    "                weighted_target_val_loss = target_val_metrics[\"loss\"] * conf.aux_weight\n",
    "                logger.add_scalar(\"val\", \"target_weighted_loss\", weighted_target_val_loss, epoch)\n",
    "                total_val_loss += target_val_metrics[\"loss\"]    \n",
    "                total_val_weighted_loss += weighted_target_val_loss\n",
    "            # total\n",
    "            logger.add_scalar(\"val\", \"loss\", total_val_loss, epoch)\n",
    "            logger.add_scalar(\"val\", \"weighted_loss\", total_val_weighted_loss, epoch)\n",
    "\n",
    "            ### Test\n",
    "            target_test_metrics = eval(net, target_test_loader, conf.device, None, use_labels=False, stage=\"Target Test\")\n",
    "            for k, v in target_test_metrics.items():\n",
    "                if 'count' not in k:\n",
    "                    logger.add_scalar(\"test\", k, v, epoch)\n",
    "            \n",
    "            # probe acc\n",
    "            if conf.plot_activations and conf.shared_backbone:\n",
    "                train_acts, train_labels = get_acts_and_labels(model, target_train_loader, conf.device)\n",
    "                test_acts, test_labels = get_acts_and_labels(net.backbone, target_test_loader, conf.device)\n",
    "                probe_acc, probe_acc_alt = compute_probe_acc(train_acts, train_labels, test_acts, test_labels, classes_per_feat)\n",
    "                logger.add_scalar(\"test\", \"probe_acc\", probe_acc, epoch)\n",
    "                logger.add_scalar(\"test\", \"probe_acc_alt\", probe_acc_alt, epoch)\n",
    "\n",
    "\n",
    "            ### Print Results\n",
    "            print(f\"Epoch {epoch + 1} Eval Results:\")\n",
    "            # print validation losses\n",
    "            if len(source_val) > 0:\n",
    "                print(f\"Source validation loss: {logger.metrics['val_source_loss'][-1]:.4f}\")\n",
    "            if len(target_val) > 0:\n",
    "                print(f\"Target validation loss {logger.metrics['val_target_loss'][-1]:.4f}\")\n",
    "            print(f\"Validation loss: {logger.metrics['val_loss'][-1]:.4f}\")\n",
    "            print(\"\\n=== Test Accuracies ===\")\n",
    "            # Overall accuracy for each head\n",
    "            print(\"\\nOverall Accuracies:\")\n",
    "            for i in range(conf.heads):\n",
    "                print(f\"Head {i}:  Main: {logger.metrics[f'test_acc_{i}'][-1]:.4f}\" + \\\n",
    "                      (f\"  |  Alt: {logger.metrics[f'test_acc_alt_{i}'][-1]:.4f}\" if not conf.use_group_labels else \"\"))\n",
    "            # Worst group accuracy for each head\n",
    "            print(\"\\nWorst Group Accuracies:\")\n",
    "            for i in range(conf.heads):\n",
    "                print(f\"Head {i}:  Worst: {logger.metrics[f'test_worst_acc_{i}'][-1]:.4f}\")\n",
    "            # Group-wise accuracies\n",
    "            print(\"\\nGroup-wise Accuracies:\")\n",
    "            for group_label in feature_label_ls(classes_per_feat):\n",
    "                print(f\"\\nGroup {group_label}, count: {target_test_metrics[f'count_{group_label}']}:\")\n",
    "                for i in range(conf.heads):\n",
    "                    print(f\"Head {i}:  Main: {logger.metrics[f'test_acc_{i}_{group_label}'][-1]:.4f}\" + \\\n",
    "                          (f\"  |  Alt: {logger.metrics[f'test_acc_alt_{i}_{group_label}'][-1]:.4f}\" if not conf.use_group_labels else \"\"))\n",
    "\n",
    "\n",
    "            # plot activations if lowest validation loss\n",
    "            if logger.metrics[\"val_loss\"][-1] == min(logger.metrics[\"val_loss\"]):\n",
    "                # plot activations \n",
    "                if conf.plot_activations and conf.shared_backbone:   \n",
    "                    # get activations \n",
    "                    activations, labels = get_acts_and_labels(net.backbone, target_test_loader, conf.device)\n",
    "                    labels = labels.to('cpu')\n",
    "                    pca_fig, pca_acts, pca_reducer = plot_activations(\n",
    "                        activations=activations, labels=labels, \n",
    "                        classes_per_feature=classes_per_feat, transform=\"pca\"\n",
    "                    )\n",
    "                    umap_fig, umap_acts, umap_reducer = plot_activations(\n",
    "                        activations=activations, labels=labels, \n",
    "                        classes_per_feature=classes_per_feat, transform=\"umap\"\n",
    "                    )\n",
    "                    pca_fig.savefig(f\"{exp_dir}/activations_{epoch}_pca.png\")\n",
    "                    pca_fig.savefig(f\"{exp_dir}/activations_{epoch}_pca.svg\")\n",
    "                    umap_fig.savefig(f\"{exp_dir}/activations_{epoch}_umap.png\")\n",
    "                    umap_fig.savefig(f\"{exp_dir}/activations_{epoch}_umap.svg\")\n",
    "                    np.save(f\"{exp_dir}/activations_{epoch}_pca.npy\", pca_acts)\n",
    "                    np.save(f\"{exp_dir}/activations_{epoch}_umap.npy\", umap_acts)\n",
    "                    plt.close(pca_fig)\n",
    "                    plt.close(umap_fig)\n",
    "            \n",
    "            net.train()\n",
    "finally:\n",
    "    logger.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diverse-gen-KG5DY0Zz-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
