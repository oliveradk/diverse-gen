{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cuda visible devices\n",
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "\n",
    "import os\n",
    "if is_notebook():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" #\"1\"\n",
    "    # os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "    # os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "import matplotlib \n",
    "if not is_notebook():\n",
    "    matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import random as rnd\n",
    "from typing import Optional, Callable\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import submitit\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as  pd\n",
    "import torchvision.utils as vision_utils\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "from losses.divdis import DivDisLoss \n",
    "from losses.divdis import DivDisLoss\n",
    "from losses.ace import ACELoss\n",
    "from losses.dbat import DBatLoss\n",
    "from losses.loss_types import LossType\n",
    "\n",
    "from models.backbone import MultiHeadBackbone\n",
    "from models.multi_model import MultiNetModel\n",
    "from models.lenet import LeNet\n",
    "from utils.utils import conf_to_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Experiment:\n",
    "    seed: int\n",
    "    loss_type: LossType\n",
    "    model: str\n",
    "    mix_rate: float\n",
    "    mix_rate_lower_bound: float\n",
    "    epochs: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "seeds = [0, 1, 2]\n",
    "losses = [LossType.PROB, LossType.DIVDIS, LossType.EXP]\n",
    "models = [\"Resnet50\"]\n",
    "# mix rates and lower bounds (same mix rate and lower bound, fixed lower bound and varying mix rate)\n",
    "mix_rates = [0.1, 0.25, 0.5, 0.75, 0.9, 1.0]\n",
    "mix_rate_lower_bounds = [0.1] # [0.1, 0.5, 1.0]\n",
    "same_mix_rate_and_lower_bounds = [\n",
    "    (mix_rate, mix_rate) for mix_rate in mix_rates\n",
    "]\n",
    "fixed_lower_bounds_and_mix_rates = list(itertools.product(\n",
    "    mix_rates, mix_rate_lower_bounds\n",
    "))\n",
    "mix_rates_and_lower_bounds = list(set(same_mix_rate_and_lower_bounds + fixed_lower_bounds_and_mix_rates))\n",
    "\n",
    "mix_rate_to_epoch: dict[float, int] = {\n",
    "    0.1: 100,\n",
    "    0.25: 100,\n",
    "    0.5: 50,\n",
    "    0.75: 50,\n",
    "    0.9: 50,\n",
    "    1.0: 50\n",
    "}\n",
    "mix_rate_to_epoch = defaultdict(lambda: 20)\n",
    "experiments: list[Experiment] = []\n",
    "\n",
    "for seed in seeds:\n",
    "    for loss in losses:\n",
    "        for model in models:\n",
    "            for mix_rate, mix_rate_lower_bound in mix_rates_and_lower_bounds:\n",
    "                epochs = mix_rate_to_epoch[mix_rate]\n",
    "                experiments.append(Experiment(seed, loss, model, mix_rate, mix_rate_lower_bound, epochs))\n",
    "print(len(experiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/ucb/oliveradk/miniforge3/envs/od_3_10/lib/python3.10/site-packages/submitit/auto/auto.py:23: UserWarning: Setting 'gres' is deprecated. Use 'slurm_gres' instead.\n",
      "  warnings.warn(f\"Setting '{arg}' is deprecated. Use '{new_arg}' instead.\")\n"
     ]
    }
   ],
   "source": [
    "out_dir = Path(\"output_logs/cifar_mnist_sweep\")\n",
    "out_dir.mkdir(exist_ok=True, parents=True)\n",
    "def get_executor(out_dir: Path):\n",
    "    executor = submitit.AutoExecutor(folder=out_dir)\n",
    "    executor.update_parameters(\n",
    "        timeout_min=60 * 48,\n",
    "        mem_gb=16,\n",
    "        gres=\"gpu:1\",\n",
    "        cpus_per_task=4,\n",
    "        nodes=1,\n",
    "        slurm_qos=\"high\",\n",
    "        slurm_array_parallelism=8\n",
    "    )\n",
    "    return executor\n",
    "def get_executor_local(out_dir: Path):\n",
    "    executor = submitit.LocalExecutor(folder=out_dir)\n",
    "    executor.update_parameters(\n",
    "        timeout_min=60 * 48,\n",
    "    )\n",
    "    return executor\n",
    "\n",
    "script_name = \"cifar_mnist.py\"\n",
    "def run_experiments(executor, experiments: list[Experiment], script_name: str):\n",
    "\n",
    "    with executor.batch():\n",
    "        jobs = []\n",
    "        for exp in experiments:\n",
    "            function = submitit.helpers.CommandFunction(\n",
    "                [\"python\", script_name] + conf_to_args(exp.__dict__)\n",
    "            )\n",
    "            jobs.append(executor.submit(function))\n",
    "    return jobs\n",
    "\n",
    "executor = get_executor(out_dir)\n",
    "# executor = get_executor_local(out_dir)\n",
    "jobs = run_experiments(executor, experiments, script_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jobs[0].stderr())\n",
    "print(jobs[0].stdout())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory from config\n",
    "result_dir = Path(\"output/cifar_mnist\")\n",
    "def exp_to_dir_name(exp: Experiment):        \n",
    "    dir_name = f\"{exp.loss_type.name}_{exp.model}_{exp.mix_rate}_{exp.mix_rate_lower_bound}_{exp.epochs}_{exp.seed}\"\n",
    "    return dir_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exp_metrics(exp: Experiment):\n",
    "    exp_dir = result_dir / exp_to_dir_name(exp)\n",
    "    # find most recent directory in exp_dir\n",
    "    most_recent_dir = sorted(exp_dir.iterdir(), key=lambda x: x.stat().st_ctime)[-1]\n",
    "    # load results.json\n",
    "    with open(most_recent_dir / \"metrics.json\", \"r\") as f:\n",
    "        exp_metrics = json.load(f)\n",
    "    return exp_metrics\n",
    "\n",
    "def get_max_acc_at_min_val_loss(exp_metrics: dict):\n",
    "    min_val_loss_idx = np.argmin(exp_metrics[\"target_val_loss\"])\n",
    "    max_acc = max(exp_metrics['epoch_acc_0'][min_val_loss_idx], exp_metrics['epoch_acc_1'][min_val_loss_idx])\n",
    "    return max_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end goal: mean and std of cifar test acc selected according to total val loss for each method across mix rates \n",
    "\n",
    "# data structure: dictionary with keys method types, values dict[mix_rate, list[len(seeds)]] of cifar accuracies (for now ignore case where mix_rate != mix_rate_lower_bound)\n",
    "results = defaultdict(lambda: defaultdict(list))\n",
    "for exp in experiments:\n",
    "    if exp.mix_rate != exp.mix_rate_lower_bound:\n",
    "        continue\n",
    "    exp_metrics = get_exp_metrics(exp)\n",
    "    max_acc = get_max_acc_at_min_val_loss(exp_metrics)\n",
    "    results[exp.loss_type][exp.mix_rate].append(max_acc)\n",
    "results = {k: dict(v) for k, v in results.items()}\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[exp for exp in experiments if exp.mix_rate_lower_bound == 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results fixed lower bound \n",
    "results_fixed_lower_bound = {lower_bound: defaultdict(lambda: defaultdict(list)) for lower_bound in mix_rate_lower_bounds}\n",
    "for lower_bound in mix_rate_lower_bounds:   \n",
    "    for exp in experiments:\n",
    "        if exp.mix_rate_lower_bound != lower_bound:\n",
    "            continue\n",
    "        exp_metrics = get_exp_metrics(exp)  \n",
    "        max_acc = get_max_acc_at_min_val_loss(exp_metrics)\n",
    "        results_fixed_lower_bound[lower_bound][exp.loss_type][exp.mix_rate].append(max_acc)\n",
    "results_fixed_lower_bound = {k: dict(v) for k, v in results_fixed_lower_bound.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mean accuracy for each method type at each mix rate\n",
    "for loss_type, loss_results in results.items():\n",
    "    plt.plot(sorted(loss_results.keys()), [np.mean(loss_results[mix_rate]) for mix_rate in sorted(loss_results.keys())], label=loss_type.name)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fixed_lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lower_bound_0_1 = results_fixed_lower_bound[0.1]\n",
    "# plot mean accuracy for each method type at each mix rate\n",
    "for loss_type, loss_results in results_lower_bound_0_1.items():\n",
    "    plt.plot(sorted(loss_results.keys()), [np.mean(loss_results[mix_rate]) for mix_rate in sorted(loss_results.keys())], label=loss_type.name)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diverse-gen-KG5DY0Zz-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
