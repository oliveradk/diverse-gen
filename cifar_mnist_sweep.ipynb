{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cuda visible devices\n",
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "\n",
    "import os\n",
    "if is_notebook():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" #\"1\"\n",
    "    # os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "    # os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "import matplotlib \n",
    "if not is_notebook():\n",
    "    matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import random as rnd\n",
    "from typing import Optional, Callable\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import submitit\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as  pd\n",
    "import torchvision.utils as vision_utils\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "from losses.divdis import DivDisLoss \n",
    "from losses.divdis import DivDisLoss\n",
    "from losses.ace import ACELoss\n",
    "from losses.dbat import DBatLoss\n",
    "from losses.loss_types import LossType\n",
    "\n",
    "from models.backbone import MultiHeadBackbone\n",
    "from models.multi_model import MultiNetModel\n",
    "from models.lenet import LeNet\n",
    "from utils.utils import conf_to_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Experiment:\n",
    "    seed: int\n",
    "    loss_type: LossType\n",
    "    model: str\n",
    "    mix_rate: float\n",
    "    mix_rate_lower_bound: float\n",
    "    epochs: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "seeds = [0]\n",
    "losses = [LossType.PROB, LossType.DIVDIS, LossType.EXP]\n",
    "models = [\"Resnet50\"]\n",
    "# mix rates and lower bounds (same mix rate and lower bound, fixed lower bound and varying mix rate)\n",
    "mix_rates = [0.1, 0.25, 0.5, 0.75, 0.9, 1.0]\n",
    "mix_rate_lower_bounds = [0.1] # [0.1, 0.5, 1.0]\n",
    "same_mix_rate_and_lower_bounds = [\n",
    "    (mix_rate, mix_rate) for mix_rate in mix_rates\n",
    "]\n",
    "fixed_lower_bounds_and_mix_rates = list(itertools.product(\n",
    "    mix_rate_lower_bounds, mix_rates\n",
    "))\n",
    "mix_rates_and_lower_bounds = same_mix_rate_and_lower_bounds + fixed_lower_bounds_and_mix_rates\n",
    "\n",
    "# mix_rate_to_epoch: dict[float, int] = {\n",
    "#     0.1: 200,\n",
    "#     0.25: 100,\n",
    "#     0.5: 20,\n",
    "#     0.75: 20,\n",
    "#     0.9: 20,\n",
    "#     1.0: 20\n",
    "# }\n",
    "mix_rate_to_epoch = defaultdict(lambda: 5)\n",
    "experiments: list[Experiment] = []\n",
    "\n",
    "for seed in seeds:\n",
    "    for loss in losses:\n",
    "        for model in models:\n",
    "            for mix_rate, mix_rate_lower_bound in mix_rates_and_lower_bounds:\n",
    "                epochs = mix_rate_to_epoch[mix_rate]\n",
    "                experiments.append(Experiment(seed, loss, model, mix_rate, mix_rate_lower_bound, epochs))\n",
    "print(len(experiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(\"output_logs/cifar_mnist_sweep\")\n",
    "out_dir.mkdir(exist_ok=True, parents=True)\n",
    "def get_executor(out_dir: Path):\n",
    "    executor = submitit.AutoExecutor(folder=out_dir)\n",
    "    executor.update_parameters(\n",
    "        timeout_min=60 * 48,\n",
    "        mem_gb=16,\n",
    "        gres=\"gpu:1\",\n",
    "        cpus_per_task=4,\n",
    "        nodes=1,\n",
    "        slurm_qos=\"high\",\n",
    "        slurm_array_parallelism=8\n",
    "    )\n",
    "def get_executor_local(out_dir: Path):\n",
    "    executor = submitit.LocalExecutor(folder=out_dir)\n",
    "    executor.update_parameters(\n",
    "        timeout_min=60 * 48,\n",
    "    )\n",
    "    return executor\n",
    "\n",
    "script_name = \"cifar_mnist.py\"\n",
    "def run_experiments(executor, experiments: list[Experiment], script_name: str):\n",
    "\n",
    "    with executor.batch():\n",
    "        jobs = []\n",
    "        for exp in experiments:\n",
    "            function = submitit.helpers.CommandFunction(\n",
    "                [\"python\", script_name] + conf_to_args(exp.__dict__)\n",
    "            )\n",
    "            jobs.append(executor.submit(function))\n",
    "    return jobs\n",
    "\n",
    "executor = get_executor(out_dir)\n",
    "# executor = get_executor_local(out_dir)\n",
    "jobs = run_experiments(executor, experiments, script_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LocalExecutor' object has no attribute 'list_jobs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError killing job \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to kill all local jobs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mkill_local_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m, in \u001b[0;36mkill_local_jobs\u001b[0;34m(out_dir)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkill_local_jobs\u001b[39m(out_dir: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Initialize the executor to get access to job information\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Get all job IDs\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     job_ids \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_jobs\u001b[49m()\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m job_id \u001b[38;5;129;01min\u001b[39;00m job_ids:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LocalExecutor' object has no attribute 'list_jobs'"
     ]
    }
   ],
   "source": [
    "import signal\n",
    "def kill_local_jobs(out_dir: str):\n",
    "    # Initialize the executor to get access to job information\n",
    "    \n",
    "    # Get all job IDs\n",
    "    job_ids = executor.list_jobs()\n",
    "    \n",
    "    for job_id in job_ids:\n",
    "        try:\n",
    "            job = executor.get_job(job_id)\n",
    "            pid = job.pid()\n",
    "            if pid is not None:\n",
    "                print(f\"Killing job {job_id} with PID {pid}\")\n",
    "                os.kill(pid, signal.SIGTERM)\n",
    "            else:\n",
    "                print(f\"Job {job_id} has no PID (might have already finished)\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error killing job {job_id}: {e}\")\n",
    "\n",
    "    print(\"Attempted to kill all local jobs\")\n",
    "kill_local_jobs(out_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diverse-gen-KG5DY0Zz-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
