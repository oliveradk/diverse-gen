{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cuda visible devices\n",
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "\n",
    "import os\n",
    "if is_notebook():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\" #\"1\"\n",
    "    # os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "    # os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "import matplotlib \n",
    "if not is_notebook():\n",
    "    matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from datasets import load_dataset\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from losses.loss_types import LossType\n",
    "from losses.ace import ACELoss\n",
    "from losses.divdis import DivDisLoss\n",
    "from losses.pass_through import PassThroughLoss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    max_length: int = 256\n",
    "    batch_size: int = 16\n",
    "    target_batch_size: int = 32\n",
    "    epochs: int = 2\n",
    "    learning_rate: float = 2e-5\n",
    "    weight_decay: float = 1e-2\n",
    "    dataset_length: int | None = None\n",
    "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    loss_type: LossType = LossType.TOPK \n",
    "    aux_weight: float = 1.0 # Weight for auxiliary loss\n",
    "    mix_rate_lower_bound: float = 0.1\n",
    "    seed: int = 42\n",
    "    exp_dir: str = f\"output/normal_data/{datetime.now().strftime('%Y%m%d_%H%M%S')}/\"\n",
    "\n",
    "def post_init(conf, overrride_keys):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = Config()\n",
    "overrride_keys = []\n",
    "if not is_notebook():\n",
    "    import sys \n",
    "    overrides = OmegaConf.from_cli(sys.argv[1:])\n",
    "    overrride_keys = overrides.keys()\n",
    "    conf_dict = OmegaConf.merge(OmegaConf.structured(conf), overrides)\n",
    "    conf = Config(**conf_dict)\n",
    "post_init(conf, overrride_keys)\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(conf.seed)\n",
    "os.makedirs(conf.exp_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, max_length=512):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataset[idx]['text']\n",
    "        label = self.dataset[idx]['label']\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions_head1 = 0\n",
    "    correct_predictions_head2 = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model({'input_ids': input_ids, 'attention_mask': attention_mask})\n",
    "            # Split outputs into two heads\n",
    "            head1_output, head2_output = outputs.split(1, dim=1)\n",
    "            \n",
    "            # Calculate loss for each head\n",
    "            loss1 = criterion(head1_output.squeeze(1), labels.float())\n",
    "            loss2 = criterion(head2_output.squeeze(1), labels.float())\n",
    "            total_loss += (loss1.item() + loss2.item()) / 2\n",
    "            \n",
    "            # Calculate accuracy for each head\n",
    "            preds_head1 = (head1_output > 0.5).squeeze(1)\n",
    "            preds_head2 = (head2_output > 0.5).squeeze(1)\n",
    "            \n",
    "            correct_predictions_head1 += (preds_head1 == labels).sum().item()\n",
    "            correct_predictions_head2 += (preds_head2 == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    acc_head1 = correct_predictions_head1 / total_predictions\n",
    "    acc_head2 = correct_predictions_head2 / total_predictions\n",
    "    \n",
    "    return avg_loss, (acc_head1, acc_head2)\n",
    "\n",
    "\n",
    "def evaluate_target(model, data_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Target Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            outputs = model({'input_ids': input_ids, 'attention_mask': attention_mask})\n",
    "            loss = loss_fn(outputs)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imdb\")\n",
    "if conf.dataset_length is not None:\n",
    "    rng = torch.Generator().manual_seed(42)  # For reproducibility\n",
    "    dataset['train'] = dataset['train'].shuffle(seed=42).select(range(conf.dataset_length))\n",
    "    dataset['test'] = dataset['test'].shuffle(seed=42).select(range(conf.dataset_length))\n",
    "    dataset['unsupervised'] = dataset['unsupervised'].shuffle(seed=42).select(range(conf.dataset_length))\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "# split training data into source_train and source_val\n",
    "source_dataset_size = len(dataset['train'])\n",
    "source_train_size = int(0.8 * source_dataset_size)  # 80-20 split\n",
    "source_val_size = source_dataset_size - source_train_size\n",
    "\n",
    "source_train_dataset, source_val_dataset = torch.utils.data.random_split(\n",
    "    dataset['train'], \n",
    "    [source_train_size, source_val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Split unsupervised data into target_train and target_val\n",
    "target_dataset_size = len(dataset['unsupervised'])\n",
    "target_train_size = int(0.8 * target_dataset_size)  # 80-20 split\n",
    "target_val_size = target_dataset_size - target_train_size\n",
    "\n",
    "target_train_dataset, target_val_dataset = torch.utils.data.random_split(\n",
    "    dataset['unsupervised'], \n",
    "    [target_train_size, target_val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "source_train_dataset = IMDBDataset(source_train_dataset, tokenizer, conf.max_length)\n",
    "source_val_dataset = IMDBDataset(source_val_dataset, tokenizer, conf.max_length)\n",
    "target_train_dataset = IMDBDataset(target_train_dataset, tokenizer, conf.max_length)\n",
    "target_val_dataset = IMDBDataset(target_val_dataset, tokenizer, conf.max_length)\n",
    "target_test_dataset = IMDBDataset(dataset['test'], tokenizer, conf.max_length)\n",
    "\n",
    "# Create data loaders\n",
    "source_train_loader = DataLoader(source_train_dataset, batch_size=conf.batch_size, shuffle=True)\n",
    "source_val_loader = DataLoader(source_val_dataset, batch_size=conf.batch_size)\n",
    "target_train_loader = DataLoader(target_train_dataset, batch_size=conf.target_batch_size, shuffle=True)\n",
    "target_val_loader = DataLoader(target_val_dataset, batch_size=conf.target_batch_size)\n",
    "target_test_loader = DataLoader(target_test_dataset, batch_size=conf.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "from models.hf_wrapper import HFWrapper\n",
    "bert_builder = lambda: BertModel.from_pretrained('bert-base-uncased')\n",
    "model_builder = lambda: HFWrapper(bert_builder())\n",
    "feature_dim = 768\n",
    "\n",
    "# Initialize model, criterion, and optimizer\n",
    "from models.backbone import MultiHeadBackbone\n",
    "feature_dim = 768  # BERT's hidden size\n",
    "classes_per_head = [1, 1]  # Binary classification for both heads\n",
    "\n",
    "model = MultiHeadBackbone(model_builder(), classes_per_head, feature_dim).to(conf.device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=conf.learning_rate, weight_decay=conf.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize loss function\n",
    "if conf.loss_type == LossType.TOPK:\n",
    "    loss_fn = ACELoss(\n",
    "        classes_per_head=[1, 1],  # Binary classification\n",
    "        mode=\"topk\",\n",
    "        device=conf.device, \n",
    "        mix_rate=conf.mix_rate_lower_bound\n",
    "    )\n",
    "elif conf.loss_type == LossType.DIVDIS:\n",
    "    loss_fn = DivDisLoss(heads=2)  # Using 2 heads\n",
    "elif conf.loss_type == LossType.ERM:\n",
    "    loss_fn = PassThroughLoss()\n",
    "else:\n",
    "    raise ValueError(f\"Loss type {conf.loss_type} not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logger import Logger\n",
    "logger = Logger(exp_dir=conf.exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from utils.utils import to_device\n",
    "\n",
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in tqdm(range(conf.epochs), desc=\"Epochs\"):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    zipped_loaders = zip(source_train_loader, cycle(target_train_loader))\n",
    "    train_iter = tqdm(zipped_loaders, total=len(source_train_loader), desc=\"Train\")\n",
    "\n",
    "    for source_batch, target_batch in train_iter:\n",
    "        # Source forward pass\n",
    "        input_ids = source_batch['input_ids'].to(conf.device)\n",
    "        attention_mask = source_batch['attention_mask'].to(conf.device)\n",
    "        labels = source_batch['label'].to(conf.device)\n",
    "        \n",
    "        source_outputs = model({'input_ids': input_ids, 'attention_mask': attention_mask})\n",
    "        source_loss = sum([criterion(source_outputs[:, i], labels.float()) for i in range(2)])\n",
    "        logger.add_scalar(\"train\", \"source_loss\", source_loss.item(), step=len(train_iter), to_metrics=False)\n",
    "        \n",
    "        # Target forward pass\n",
    "        target_input_ids = target_batch['input_ids'].to(conf.device)\n",
    "        target_attention_mask = target_batch['attention_mask'].to(conf.device)\n",
    "        \n",
    "        target_outputs = model({'input_ids': target_input_ids, 'attention_mask': target_attention_mask})\n",
    "        target_loss = loss_fn(target_outputs)\n",
    "        logger.add_scalar(\"train\", \"target_loss\", target_loss.item(), step=len(train_iter), to_metrics=False)\n",
    "        # Combined loss\n",
    "        loss = source_loss + conf.aux_weight * target_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    source_val_loss, (source_val_acc_1, source_val_acc_2) = evaluate(model, source_val_loader, criterion, conf.device)\n",
    "    target_val_loss = evaluate_target(model, target_val_loader, loss_fn, conf.device)\n",
    "    total_val_loss = source_val_loss + target_val_loss\n",
    "    logger.add_scalar(\"val\", \"source_loss\", source_val_loss, step=epoch)\n",
    "    logger.add_scalar(\"val\", \"target_loss\", target_val_loss, step=epoch)\n",
    "    # Test Accuracy for each head\n",
    "    test_loss, (test_acc_head1, test_acc_head2) = evaluate(model, target_test_loader, criterion, conf.device)\n",
    "    logger.add_scalar(\"test\", \"acc_1\", test_acc_head1, step=epoch)\n",
    "    logger.add_scalar(\"test\", \"acc_2\", test_acc_head2, step=epoch)\n",
    "    \n",
    "    print(f\"Train Loss: {total_loss/len(source_train_loader):.4f}\")\n",
    "    print(f\"Source Val Loss: {source_val_loss:.4f}, Source Val Acc: Head 1: {source_val_acc_1:.4f}, Head 2: {source_val_acc_2:.4f}\")\n",
    "    print(f\"Target Val Loss: {target_val_loss:.4f}\")\n",
    "    print(f\"Total Val Loss: {total_val_loss:.4f}\")\n",
    "    print(f\"Test Accuracy - Head 1: {test_acc_head1:.4f}, Head 2: {test_acc_head2:.4f}\")\n",
    "    \n",
    "    if total_val_loss < best_val_loss:\n",
    "        best_val_loss = total_val_loss\n",
    "        torch.save(model.state_dict(), f'{conf.exp_dir}/best_model.pt')\n",
    "        print(\"Saved best model!\")\n",
    "\n",
    "logger.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "od_3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
